{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "For this homework, you will be working extensively in tensorflow. It is suggested that you spin up a Google Cloud VM with a GPU attached. Remember, instructions for doing so are found in Homework 0.\n",
    "\n",
    "### Part 1: Homework 2, but on tensorflow\n",
    "### Part 2: DNN on MNIST and CIFAR10\n",
    "### Part 3: VGG on MNIST and CIFAR10\n",
    "### (Optional) Part 4, getting state of the art (#SOTA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 1\n",
    "You don't have to repeat everything in homework 2, but rather pick one set of two features that worked well for you last homework, and implement logistic regression using tensorflow without using keras (you will practice using keras in parts 2 and 3). In other words, using tensorflow operations, please create a scalar-value loss function and let tensorflow create the training operation for logistic regression, which automatically computes the gradients and updates the weight parameters. Note that the logistic loss is a special case of the softmax cross entropy loss that you've seen when classifying MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(324, 3)\n",
      "(37, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets\n",
    "%matplotlib inline\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "number_a = 0\n",
    "number_b = 3\n",
    "\n",
    "digit_a_indexes = np.where(digits.target==number_a) \n",
    "digit_b_indexes = np.where(digits.target==number_b)\n",
    "targets = np.concatenate((digits.target[digit_a_indexes], digits.target[digit_b_indexes]))\n",
    "images = np.concatenate((digits.images[digit_a_indexes], digits.images[digit_b_indexes]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, targets, test_size=0.1, random_state=42)\n",
    "\n",
    "def compute_features(vector):\n",
    "    image = vector.reshape(8, 8) # get back original image shape\n",
    "    def compute_feature_a(image):\n",
    "        return image.std()**2\n",
    "    def compute_feature_b(image):\n",
    "        return np.mean(image)\n",
    "    return compute_feature_a(image), compute_feature_b(image)\n",
    "# for x train dataset\n",
    "X_features_train = np.apply_along_axis(compute_features, 1, \n",
    "                                       X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
    "X_features_a = X_features_train[np.where(y_train==number_a)]\n",
    "X_features_b = X_features_train[np.where(y_train==number_b)]\n",
    "# for x test dataset\n",
    "X_features_test = np.apply_along_axis(compute_features, 1, \n",
    "                                      X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]))\n",
    "X_features_a_test = X_features_test[np.where(y_test==number_a)]\n",
    "X_features_b_test = X_features_test[np.where(y_test==number_b)]\n",
    "\n",
    "# add Bias: \n",
    "X_features_train = np.insert(X_features_train, 2, 1, axis = 1)\n",
    "print(X_features_train.shape)\n",
    "X_features_test = np.insert(X_features_test, 2, 1, axis = 1)\n",
    "print(X_features_test.shape)\n",
    "\n",
    "# for y train\n",
    "y_train_label = np.copy(y_train)\n",
    "y_train_label[y_train == number_a] = 0\n",
    "y_train_label[y_train == number_b] = 1\n",
    "y_train_label = np.expand_dims(y_train_label, 1)\n",
    "# for y test\n",
    "y_test_label = np.copy(y_test)\n",
    "y_test_label[y_test == number_a] = 0\n",
    "y_test_label[y_test == number_b] = 1\n",
    "y_test_label = np.expand_dims(y_test_label, 1)\n",
    "\n",
    "# cast as a float32; in general, you will work with float32 inputs:\n",
    "X_features_train = X_features_train.astype(np.float32)\n",
    "y_train_label = y_train_label.astype(np.float32)\n",
    "\n",
    "X_train_or_test = tf.placeholder(tf.float32, [None, 3], name='input_features')\n",
    "y_train_or_test = tf.placeholder(tf.float32, [None, 1], name='image_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metrics(predicted, label):\n",
    "    return np.mean((predicted == 0) == (label == 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loss:  0.021393431\n",
      "Weight:  [[0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Train Accuracy:  0.4845679012345679\n",
      "Loss:  -0.0364431\n",
      "Weight:  [[3.3649614e-03]\n",
      " [4.8596089e-04]\n",
      " [9.9805569e-05]]\n",
      "Train Accuracy:  0.5154320987654321\n",
      "Loss:  -0.09356081\n",
      "Weight:  [[0.00670872]\n",
      " [0.00097038]\n",
      " [0.00019921]]\n",
      "Train Accuracy:  0.5154320987654321\n",
      "Loss:  -0.14998037\n",
      "Weight:  [[0.01003176]\n",
      " [0.00145332]\n",
      " [0.00029821]]\n",
      "Train Accuracy:  0.5154320987654321\n",
      "Loss:  -0.20572914\n",
      "Weight:  [[0.01333475]\n",
      " [0.00193482]\n",
      " [0.00039684]]\n",
      "Train Accuracy:  0.5154320987654321\n"
     ]
    }
   ],
   "source": [
    "weights = tf.Variable(np.zeros((3,1)), dtype=np.float32)\n",
    "p = tf.sigmoid(tf.matmul(X_train_or_test, weights))\n",
    "log_loss = tf.reduce_mean(-(y_train_or_test*tf.log(p))+(1-y_train_or_test)*tf.log(1-p))\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.00001).minimize(log_loss)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "losses = list()\n",
    "for i in range(100):\n",
    "    loss_i, weight_i, _ = sess.run([log_loss, weights, train_op],\n",
    "                                   feed_dict={X_train_or_test: X_features_train, y_train_or_test: y_train_label})\n",
    "    losses.append(loss_i)\n",
    "    if i%20 == 0:\n",
    "        print(\"Loss: \", loss_i)\n",
    "        print(\"Weight: \", weight_i)\n",
    "        print(\"Train Accuracy: \", accuracy_metrics(X_features_train@weight_i, y_train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_model(features, labels, weights, y):\n",
    "    a = np.linspace(-100, 100, num = 1000)\n",
    "    if len(weights) == 2:\n",
    "        b = - weights[0] * a / weights[1] # add weights[2] into formula\n",
    "    elif len(weights) == 3:\n",
    "        b = - (weights[0] * a + weights[2]) / weights[1]    \n",
    "    features_a = features[np.where(y==number_a)]\n",
    "    features_b = features[np.where(y==number_b)]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(features_a[:, 0], features_a[:, 1], '.')\n",
    "    plt.plot(features_b[:, 0], features_b[:, 1], '.')\n",
    "    plt.plot(a, b)\n",
    "    plt.xlabel('feature_a')\n",
    "    plt.ylabel('feature_b')\n",
    "    plt.ylim(features[:, 1].min(), features[:, 1].max())\n",
    "    \n",
    "visualize_model(X_features_test, y_test_label, weight_i, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflections on Part 1\n",
    "I encountered similar bug from Homework2, which I wasn't able to figure out. I hope besides this bug, the rest of code look more reasonable. The bug I had gave me NaN for loss and weights after several runs. I found out when the learning rate is too large, my predicted Y: tf.sigmoid(tf.matmul(X_train_or_test, weights)) will become all ones. Please let me know which line of code is causing the error.\n",
    "Thanks"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2:  DNN on MNIST and CIFAR10\n",
    "\n",
    "In our lab, you guys saw how to work with the MNIST dataset to perform image classification. We can attempt the MNIST classification problem with just fully connected layers. This means we will be optimizing for non-banded matrices (no convolutions).\n",
    "\n",
    "1. Calcualte the number of weight parameters you are optimizing for 1, 2 and 3 different fully connected layers (the total size of each layer is up to you).\n",
    "2. What is the max layer depth you can go before training loss does not converge? You can usually tell that something is not converging by examining the training loss vs. iteration curve.\n",
    "3. How does the number of parameters relate to the training loss and validation/test loss? Try to get a few data points to speak to this question.\n",
    "3. Keeping the maximum number of parameters possible while still maintaining convergence (i.e., a good training and validation/test loss), what happens when you swap the activation function to `tanh` instead of `relu`? How about `sigmoid`?\n",
    "4. After exploring the above, train a DNN model with the combination of hyperparameters that you believe will work best on MNIST.\n",
    "5. Using the same architecture, try training a DNN model on more difficult dataset such as Fashion MNIST or CIFAR10/100. Example download instructions are shown in the next problem.\n",
    "\n",
    "### Must haves\n",
    "1. Make a curve of the final validation/test loss of your DNN after the loss plateaus as a function of the number of weight parameters used (final loss versus # parameters used). Note that you might see something like the curve below for a low number of parameters, but as the number of parameters increases, it will not look like this plot. \n",
    "2. On the same figure, make the same curve as above, but use different activation functions in your architecture.\n",
    "3. Plot a point corresponding to your crafted DNN archiecture for question 4.\n",
    "4. Repeat 1-3 for CIFAR10\n",
    "\n",
    "The curves when reasonable # params are used look like the below\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = []\n",
    "train_error = []\n",
    "test_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "Training data shape (60000, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(X_train, y_train), (X_val, y_val) = tf.keras.datasets.mnist.load_data() #load dataset\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, 10)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Training data shape', X_train.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train[0].reshape(28, 28), cmap=plt.cm.Greys);\n",
    "ax2.imshow(X_train[1].reshape(28, 28), cmap=plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 11.5011 - acc: 0.2860 - val_loss: 11.2560 - val_acc: 0.3014\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 11.2682 - acc: 0.3008 - val_loss: 11.1585 - val_acc: 0.3077\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 11.2578 - acc: 0.3014 - val_loss: 11.1988 - val_acc: 0.3051\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 11.1971 - acc: 0.3052 - val_loss: 11.1650 - val_acc: 0.3073\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 11.2056 - acc: 0.3047 - val_loss: 11.2123 - val_acc: 0.3043\n",
      "train_error:  [69.48]\n",
      "test_error:  [69.23]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 14.4876 - acc: 0.1011 - val_loss: 14.4918 - val_acc: 0.1009\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 14.5200 - acc: 0.0992 - val_loss: 14.4918 - val_acc: 0.1009\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 14.5200 - acc: 0.0992 - val_loss: 14.4918 - val_acc: 0.1009\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 14.5200 - acc: 0.0992 - val_loss: 14.4918 - val_acc: 0.1009\n",
      "train_error:  [69.48, 89.89]\n",
      "test_error:  [69.23, 89.91]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 109,810\n",
      "Trainable params: 109,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 14.3036 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "train_error:  [69.48, 89.89, 88.75833333333334]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 130,010\n",
      "Trainable params: 130,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 14.3056 - acc: 0.1122 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 150,210\n",
      "Trainable params: 150,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.5214 - acc: 0.8704 - val_loss: 0.2725 - val_acc: 0.9282\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2553 - acc: 0.9363 - val_loss: 0.2548 - val_acc: 0.9355\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.2279 - acc: 0.9461 - val_loss: 0.2126 - val_acc: 0.9505\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2247 - acc: 0.9481 - val_loss: 0.2254 - val_acc: 0.9482\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2187 - acc: 0.9482 - val_loss: 0.4387 - val_acc: 0.8508\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 170,410\n",
      "Trainable params: 170,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.4620 - acc: 0.8763 - val_loss: 0.2942 - val_acc: 0.9274\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2568 - acc: 0.9383 - val_loss: 0.2705 - val_acc: 0.9376\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.8993 - acc: 0.7186 - val_loss: 1.7899 - val_acc: 0.2730\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 5.3291 - acc: 0.2116 - val_loss: 14.4612 - val_acc: 0.1028\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 14.4349 - acc: 0.1044 - val_loss: 14.4612 - val_acc: 0.1028\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996, 6.164999999999998]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999, 6.240000000000001]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 190,610\n",
      "Trainable params: 190,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.5829 - acc: 0.8322 - val_loss: 0.7799 - val_acc: 0.8084\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 1.0128 - acc: 0.7011 - val_loss: 1.2979 - val_acc: 0.5151\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 1.0302 - acc: 0.6542 - val_loss: 0.8175 - val_acc: 0.7216\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.8444 - acc: 0.7751 - val_loss: 0.5643 - val_acc: 0.8728\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.7573 - acc: 0.8276 - val_loss: 4.0585 - val_acc: 0.5503\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996, 6.164999999999998, 16.77833333333333]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999, 6.240000000000001, 12.719999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 210,810\n",
      "Trainable params: 210,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.6717 - acc: 0.7853 - val_loss: 0.4036 - val_acc: 0.9073\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 1.0197 - acc: 0.6789 - val_loss: 2.2740 - val_acc: 0.1267\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 2.4770 - acc: 0.1193 - val_loss: 2.3017 - val_acc: 0.1028\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 2.3018 - acc: 0.1113 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996, 6.164999999999998, 16.77833333333333, 21.471666666666668]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999, 6.240000000000001, 12.719999999999999, 9.27]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 231,010\n",
      "Trainable params: 231,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.9890 - acc: 0.6604 - val_loss: 0.8173 - val_acc: 0.7421\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 1.2089 - acc: 0.5870 - val_loss: 0.9364 - val_acc: 0.7092\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.9755 - acc: 0.6920 - val_loss: 0.9151 - val_acc: 0.6831\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 1.2171 - acc: 0.5723 - val_loss: 0.9420 - val_acc: 0.7201\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996, 6.164999999999998, 16.77833333333333, 21.471666666666668, 30.801666666666673]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999, 6.240000000000001, 12.719999999999999, 9.27, 25.790000000000003]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 251,210\n",
      "Trainable params: 251,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 1.2805 - acc: 0.5147 - val_loss: 1.8658 - val_acc: 0.3024\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 1.2121 - acc: 0.5499 - val_loss: 1.4051 - val_acc: 0.4730\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.9845 - acc: 0.6429 - val_loss: 1.0285 - val_acc: 0.6389\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.8540 - acc: 0.7322 - val_loss: 0.7845 - val_acc: 0.7780\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 1.7038 - acc: 0.7028 - val_loss: 2.3412 - val_acc: 0.6687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996, 6.164999999999998, 16.77833333333333, 21.471666666666668, 30.801666666666673, 26.775000000000006]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999, 6.240000000000001, 12.719999999999999, 9.27, 25.790000000000003, 22.199999999999996]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,410\n",
      "Trainable params: 271,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 1.2224 - acc: 0.5270 - val_loss: 0.9410 - val_acc: 0.6600\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.9936 - acc: 0.6586 - val_loss: 0.9490 - val_acc: 0.6394\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 1.1757 - acc: 0.5948 - val_loss: 0.9615 - val_acc: 0.6421\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 1.9054 - acc: 0.4564 - val_loss: 2.3026 - val_acc: 0.1135\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996, 6.164999999999998, 16.77833333333333, 21.471666666666668, 30.801666666666673, 26.775000000000006, 34.145]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999, 6.240000000000001, 12.719999999999999, 9.27, 25.790000000000003, 22.199999999999996, 34.0]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 291,610\n",
      "Trainable params: 291,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 13s 208us/step - loss: 1.4733 - acc: 0.5457 - val_loss: 1.1263 - val_acc: 0.6270\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 1.0390 - acc: 0.6464 - val_loss: 1.3618 - val_acc: 0.5338\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 1.2024 - acc: 0.5922 - val_loss: 0.8975 - val_acc: 0.6923\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 12.3865 - acc: 0.1938 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996, 6.164999999999998, 16.77833333333333, 21.471666666666668, 30.801666666666673, 26.775000000000006, 34.145, 35.36166666666667]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999, 6.240000000000001, 12.719999999999999, 9.27, 25.790000000000003, 22.199999999999996, 34.0, 30.769999999999996]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_12 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 311,810\n",
      "Trainable params: 311,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 2.3040 - acc: 0.1124 - val_loss: 2.3014 - val_acc: 0.1135\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 2.3017 - acc: 0.1124 - val_loss: 2.3012 - val_acc: 0.1135\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 2.3017 - acc: 0.1117 - val_loss: 2.3019 - val_acc: 0.1135\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 2.3018 - acc: 0.1111 - val_loss: 2.3015 - val_acc: 0.1135\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996, 6.164999999999998, 16.77833333333333, 21.471666666666668, 30.801666666666673, 26.775000000000006, 34.145, 35.36166666666667, 88.76333333333332]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999, 6.240000000000001, 12.719999999999999, 9.27, 25.790000000000003, 22.199999999999996, 34.0, 30.769999999999996, 88.64999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 332,010\n",
      "Trainable params: 332,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 1.2553 - acc: 0.5309 - val_loss: 0.8293 - val_acc: 0.7306\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 1.0008 - acc: 0.6525 - val_loss: 1.1816 - val_acc: 0.5415\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 1.1784 - acc: 0.5720 - val_loss: 0.7670 - val_acc: 0.7735\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.9850 - acc: 0.6736 - val_loss: 0.8979 - val_acc: 0.7001\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.9125 - acc: 0.6940 - val_loss: 1.3130 - val_acc: 0.5098\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996, 6.164999999999998, 16.77833333333333, 21.471666666666668, 30.801666666666673, 26.775000000000006, 34.145, 35.36166666666667, 88.76333333333332, 30.60166666666667]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999, 6.240000000000001, 12.719999999999999, 9.27, 25.790000000000003, 22.199999999999996, 34.0, 30.769999999999996, 88.64999999999999, 22.650000000000002]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_14 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 352,210\n",
      "Trainable params: 352,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 2.3056 - acc: 0.1098 - val_loss: 2.3016 - val_acc: 0.1135\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 2.3016 - acc: 0.1127 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 2.3017 - acc: 0.1121 - val_loss: 2.3012 - val_acc: 0.1135\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 2.3017 - acc: 0.1119 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996, 6.164999999999998, 16.77833333333333, 21.471666666666668, 30.801666666666673, 26.775000000000006, 34.145, 35.36166666666667, 88.76333333333332, 30.60166666666667, 88.72666666666666]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999, 6.240000000000001, 12.719999999999999, 9.27, 25.790000000000003, 22.199999999999996, 34.0, 30.769999999999996, 88.64999999999999, 22.650000000000002, 88.64999999999999]\n"
     ]
    }
   ],
   "source": [
    "n = 15 # number of test\n",
    "for i in range(n):\n",
    "    model = tf.keras.Sequential([])\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28, 1)))\n",
    "    for j in range(i):\n",
    "        model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "    for k in range(i):\n",
    "        model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    parameters.append(model.count_params())  #count parameters for you\n",
    "\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.005),\n",
    "                  loss='categorical_crossentropy', #10 classes for output\n",
    "                  metrics=['accuracy']) # add mae: mean average error\n",
    "    model.summary()\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "    # tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs/{}'.format('model_name'))\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                         batch_size=64,\n",
    "                         epochs=5,\n",
    "                         verbose=1,\n",
    "                         validation_data=(X_val, y_val),\n",
    "                         callbacks=[early_stop])\n",
    "    train_error.append(100*(1-max(hist.history['acc'])))\n",
    "    print('train_error: ', train_error)\n",
    "    test_error.append(100*(1-max(hist.history['val_acc'])))\n",
    "    print('test_error: ', test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(parameters_list, train_errors_list, test_errors_list):\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(parameters_list, train_errors_list,'r', label='train error')\n",
    "    ax.plot(parameters_list, test_errors_list,'g', label='test error')\n",
    "    ax.set(xlabel='# parameters', ylabel='validation error (%)')\n",
    "    ax.legend()\n",
    "    plt.title('Tanh Multiple Layers')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter list:  [7850, 89610, 109810, 130010, 150210, 170410, 190610, 210810, 231010, 251210, 271410, 291610, 311810, 332010, 352210]\n",
      "train_error:  [69.48, 89.89, 88.75833333333334, 88.76333333333332, 5.174999999999996, 6.164999999999998, 16.77833333333333, 21.471666666666668, 30.801666666666673, 26.775000000000006, 34.145, 35.36166666666667, 88.76333333333332, 30.60166666666667, 88.72666666666666]\n",
      "test_error:  [69.23, 89.91, 88.64999999999999, 88.64999999999999, 4.949999999999999, 6.240000000000001, 12.719999999999999, 9.27, 25.790000000000003, 22.199999999999996, 34.0, 30.769999999999996, 88.64999999999999, 22.650000000000002, 88.64999999999999]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('parameter list: ', parameters)\n",
    "print('train_error: ', train_error)\n",
    "print('test_error: ', test_error)\n",
    "plot_loss(parameters, train_error, test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 6.9413 - acc: 0.5628 - val_loss: 4.9777 - val_acc: 0.6857\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.7359 - acc: 0.7015 - val_loss: 4.4802 - val_acc: 0.7185\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.5507 - acc: 0.7140 - val_loss: 4.4140 - val_acc: 0.7231\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.4713 - acc: 0.7195 - val_loss: 4.2209 - val_acc: 0.7358\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.4173 - acc: 0.7233 - val_loss: 4.3496 - val_acc: 0.7279\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.4157 - acc: 0.7237 - val_loss: 4.2027 - val_acc: 0.7368\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.3449 - acc: 0.7281 - val_loss: 4.2125 - val_acc: 0.7372\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.3404 - acc: 0.7288 - val_loss: 4.2325 - val_acc: 0.7351\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.3704 - acc: 0.7270 - val_loss: 4.2645 - val_acc: 0.7331\n",
      "train_error:  [27.125]\n",
      "test_error:  [26.280000000000005]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 85,170\n",
      "Trainable params: 85,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.6355 - acc: 0.8049 - val_loss: 0.5089 - val_acc: 0.8393\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.4183 - acc: 0.8697 - val_loss: 0.3589 - val_acc: 0.8892\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.4041 - acc: 0.8711 - val_loss: 0.3499 - val_acc: 0.8920\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.3617 - acc: 0.8883 - val_loss: 0.3433 - val_acc: 0.8939\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.3322 - acc: 0.8953 - val_loss: 0.3290 - val_acc: 0.8985\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.3058 - acc: 0.9047 - val_loss: 0.2789 - val_acc: 0.9135\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2911 - acc: 0.9093 - val_loss: 0.3032 - val_acc: 0.9038\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.3005 - acc: 0.9037 - val_loss: 0.2645 - val_acc: 0.9198\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2644 - acc: 0.9163 - val_loss: 0.2483 - val_acc: 0.9240\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2558 - acc: 0.9201 - val_loss: 0.2437 - val_acc: 0.9272\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2540 - acc: 0.9206 - val_loss: 0.2492 - val_acc: 0.9212\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2550 - acc: 0.9191 - val_loss: 0.2495 - val_acc: 0.9217\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2506 - acc: 0.9218 - val_loss: 0.2659 - val_acc: 0.9144\n",
      "train_error:  [27.125, 7.820000000000005]\n",
      "test_error:  [26.280000000000005, 7.279999999999998]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 98,930\n",
      "Trainable params: 98,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.5705 - acc: 0.8191 - val_loss: 0.4589 - val_acc: 0.8476\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3827 - acc: 0.8787 - val_loss: 0.3364 - val_acc: 0.8939\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.3551 - acc: 0.8875 - val_loss: 0.3074 - val_acc: 0.9018\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3223 - acc: 0.8975 - val_loss: 0.3133 - val_acc: 0.9000\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3228 - acc: 0.8956 - val_loss: 0.3148 - val_acc: 0.9022\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3175 - acc: 0.8988 - val_loss: 0.3208 - val_acc: 0.8983\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 112,690\n",
      "Trainable params: 112,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.5884 - acc: 0.8111 - val_loss: 0.4539 - val_acc: 0.8513\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.4337 - acc: 0.8609 - val_loss: 0.3892 - val_acc: 0.8726\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.3742 - acc: 0.8818 - val_loss: 0.3493 - val_acc: 0.8928\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.3503 - acc: 0.8881 - val_loss: 0.3348 - val_acc: 0.8916\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.3244 - acc: 0.8966 - val_loss: 0.2800 - val_acc: 0.9112\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2990 - acc: 0.9057 - val_loss: 0.2894 - val_acc: 0.9093\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3030 - acc: 0.9033 - val_loss: 0.2842 - val_acc: 0.9119\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2809 - acc: 0.9107 - val_loss: 0.2820 - val_acc: 0.9129\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 126,450\n",
      "Trainable params: 126,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.6383 - acc: 0.7945 - val_loss: 0.5252 - val_acc: 0.8295\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.4681 - acc: 0.8516 - val_loss: 0.4391 - val_acc: 0.8581\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.4108 - acc: 0.8689 - val_loss: 0.3887 - val_acc: 0.8796\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.3704 - acc: 0.8825 - val_loss: 0.3889 - val_acc: 0.8784\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.3581 - acc: 0.8871 - val_loss: 0.3383 - val_acc: 0.8937\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.3437 - acc: 0.8905 - val_loss: 0.3441 - val_acc: 0.8899\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3267 - acc: 0.8966 - val_loss: 0.3099 - val_acc: 0.9022\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3055 - acc: 0.9030 - val_loss: 0.3207 - val_acc: 0.8983\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2929 - acc: 0.9084 - val_loss: 0.2993 - val_acc: 0.9072\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2916 - acc: 0.9091 - val_loss: 0.3304 - val_acc: 0.8975\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.2953 - acc: 0.9061 - val_loss: 0.2981 - val_acc: 0.9053\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2847 - acc: 0.9110 - val_loss: 0.2705 - val_acc: 0.9146\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2688 - acc: 0.9159 - val_loss: 0.3001 - val_acc: 0.9035\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2689 - acc: 0.9160 - val_loss: 0.2801 - val_acc: 0.9129\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2646 - acc: 0.9175 - val_loss: 0.2622 - val_acc: 0.9183\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 140,210\n",
      "Trainable params: 140,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.6501 - acc: 0.7912 - val_loss: 0.4960 - val_acc: 0.8434\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.4622 - acc: 0.8527 - val_loss: 0.4492 - val_acc: 0.8554\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.4417 - acc: 0.8597 - val_loss: 0.4595 - val_acc: 0.8521\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.4248 - acc: 0.8652 - val_loss: 0.3661 - val_acc: 0.8853\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3955 - acc: 0.8741 - val_loss: 0.3947 - val_acc: 0.8735\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.3592 - acc: 0.8869 - val_loss: 0.3462 - val_acc: 0.8917\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.3345 - acc: 0.8955 - val_loss: 0.3237 - val_acc: 0.9016\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3307 - acc: 0.8945 - val_loss: 0.3440 - val_acc: 0.8906\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.3381 - acc: 0.8923 - val_loss: 0.3310 - val_acc: 0.8989\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3264 - acc: 0.8972 - val_loss: 0.3163 - val_acc: 0.9000\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2955 - acc: 0.9083 - val_loss: 0.2752 - val_acc: 0.9189\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.2916 - acc: 0.9096 - val_loss: 0.2901 - val_acc: 0.9121\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2837 - acc: 0.9114 - val_loss: 0.2716 - val_acc: 0.9193\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2748 - acc: 0.9138 - val_loss: 0.2797 - val_acc: 0.9122\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2781 - acc: 0.9142 - val_loss: 0.2811 - val_acc: 0.9143\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334, 8.579999999999998]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17, 8.07]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 153,970\n",
      "Trainable params: 153,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.6561 - acc: 0.7891 - val_loss: 0.5309 - val_acc: 0.8341\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.4848 - acc: 0.8474 - val_loss: 0.4618 - val_acc: 0.8567\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.4279 - acc: 0.8665 - val_loss: 0.4113 - val_acc: 0.8742\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.4087 - acc: 0.8733 - val_loss: 0.3697 - val_acc: 0.8907\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.3729 - acc: 0.8843 - val_loss: 0.3706 - val_acc: 0.8839\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.3809 - acc: 0.8809 - val_loss: 0.3814 - val_acc: 0.8847\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3723 - acc: 0.8827 - val_loss: 0.3234 - val_acc: 0.8997\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.3308 - acc: 0.8989 - val_loss: 0.3269 - val_acc: 0.8958\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.3561 - acc: 0.8881 - val_loss: 0.3285 - val_acc: 0.8981\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.3278 - acc: 0.8992 - val_loss: 0.3116 - val_acc: 0.9057\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.3108 - acc: 0.9050 - val_loss: 0.3272 - val_acc: 0.8989\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2947 - acc: 0.9084 - val_loss: 0.3014 - val_acc: 0.9110\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.2924 - acc: 0.9108 - val_loss: 0.2882 - val_acc: 0.9147\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2921 - acc: 0.9101 - val_loss: 0.3019 - val_acc: 0.9094\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.2802 - acc: 0.9146 - val_loss: 0.2742 - val_acc: 0.9151\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334, 8.579999999999998, 8.53666666666667]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17, 8.07, 8.489999999999998]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 167,730\n",
      "Trainable params: 167,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.6906 - acc: 0.7798 - val_loss: 0.5171 - val_acc: 0.8348\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.5170 - acc: 0.8377 - val_loss: 0.5303 - val_acc: 0.8295\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.4793 - acc: 0.8503 - val_loss: 0.4956 - val_acc: 0.8448\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.4596 - acc: 0.8551 - val_loss: 0.4113 - val_acc: 0.8721\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.4012 - acc: 0.8754 - val_loss: 0.3697 - val_acc: 0.8865\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.3914 - acc: 0.8791 - val_loss: 0.3570 - val_acc: 0.8910\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.3635 - acc: 0.8876 - val_loss: 0.3540 - val_acc: 0.8929\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.3812 - acc: 0.8810 - val_loss: 0.4025 - val_acc: 0.8770\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3588 - acc: 0.8885 - val_loss: 0.3434 - val_acc: 0.8946\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.3457 - acc: 0.8941 - val_loss: 0.3309 - val_acc: 0.8983\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.3082 - acc: 0.9060 - val_loss: 0.3075 - val_acc: 0.9079\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3108 - acc: 0.9052 - val_loss: 0.3359 - val_acc: 0.8999\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.3217 - acc: 0.9022 - val_loss: 0.3133 - val_acc: 0.9042\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.3023 - acc: 0.9094 - val_loss: 0.3047 - val_acc: 0.9100\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.2865 - acc: 0.9149 - val_loss: 0.3264 - val_acc: 0.9009\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334, 8.579999999999998, 8.53666666666667, 8.506666666666662]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17, 8.07, 8.489999999999998, 8.999999999999996]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 181,490\n",
      "Trainable params: 181,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.7082 - acc: 0.7729 - val_loss: 0.6246 - val_acc: 0.7967\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.5716 - acc: 0.8196 - val_loss: 0.5279 - val_acc: 0.8354\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.5132 - acc: 0.8412 - val_loss: 0.4240 - val_acc: 0.8744\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.4807 - acc: 0.8514 - val_loss: 0.4436 - val_acc: 0.8642\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.4498 - acc: 0.8627 - val_loss: 0.4281 - val_acc: 0.8699\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.4032 - acc: 0.8775 - val_loss: 0.3887 - val_acc: 0.8803\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.3872 - acc: 0.8818 - val_loss: 0.3551 - val_acc: 0.8949\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.3778 - acc: 0.8830 - val_loss: 0.4260 - val_acc: 0.8720\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.3763 - acc: 0.8847 - val_loss: 0.3829 - val_acc: 0.8834\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3688 - acc: 0.8868 - val_loss: 0.3971 - val_acc: 0.8752\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334, 8.579999999999998, 8.53666666666667, 8.506666666666662, 11.31833333333333]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17, 8.07, 8.489999999999998, 8.999999999999996, 10.509999999999998]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 195,250\n",
      "Trainable params: 195,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.7545 - acc: 0.7580 - val_loss: 0.5716 - val_acc: 0.8252\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.5648 - acc: 0.8250 - val_loss: 0.5091 - val_acc: 0.8460\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.4958 - acc: 0.8485 - val_loss: 0.5436 - val_acc: 0.8340\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.4816 - acc: 0.8550 - val_loss: 0.4246 - val_acc: 0.8757\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.4587 - acc: 0.8614 - val_loss: 0.4461 - val_acc: 0.8617\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.4488 - acc: 0.8646 - val_loss: 0.4109 - val_acc: 0.8816\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.4214 - acc: 0.8728 - val_loss: 0.3772 - val_acc: 0.8894\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.3772 - acc: 0.8888 - val_loss: 0.4211 - val_acc: 0.8643\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.3758 - acc: 0.8869 - val_loss: 0.3878 - val_acc: 0.8846\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.3994 - acc: 0.8826 - val_loss: 0.3759 - val_acc: 0.8963\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3727 - acc: 0.8890 - val_loss: 0.3966 - val_acc: 0.8787\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.3533 - acc: 0.8945 - val_loss: 0.3470 - val_acc: 0.9012\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.3732 - acc: 0.8879 - val_loss: 0.3588 - val_acc: 0.8951\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.3812 - acc: 0.8852 - val_loss: 0.4205 - val_acc: 0.8734\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.3596 - acc: 0.8951 - val_loss: 0.4160 - val_acc: 0.8766\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334, 8.579999999999998, 8.53666666666667, 8.506666666666662, 11.31833333333333, 10.495]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17, 8.07, 8.489999999999998, 8.999999999999996, 10.509999999999998, 9.879999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 209,010\n",
      "Trainable params: 209,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.8126 - acc: 0.7416 - val_loss: 0.5936 - val_acc: 0.8168\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.6136 - acc: 0.8089 - val_loss: 0.5782 - val_acc: 0.8169\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.5324 - acc: 0.8394 - val_loss: 0.4954 - val_acc: 0.8516\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.5194 - acc: 0.8410 - val_loss: 0.4933 - val_acc: 0.8530\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.4583 - acc: 0.8642 - val_loss: 0.4342 - val_acc: 0.8725\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.4420 - acc: 0.8677 - val_loss: 0.4309 - val_acc: 0.8677\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.4588 - acc: 0.8628 - val_loss: 0.4518 - val_acc: 0.8675\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.4408 - acc: 0.8700 - val_loss: 0.4124 - val_acc: 0.8763\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.4365 - acc: 0.8745 - val_loss: 0.4482 - val_acc: 0.8692\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.4188 - acc: 0.8776 - val_loss: 0.4068 - val_acc: 0.8796\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.4269 - acc: 0.8729 - val_loss: 0.4364 - val_acc: 0.8696\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.3719 - acc: 0.8937 - val_loss: 0.3637 - val_acc: 0.8976\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.3909 - acc: 0.8862 - val_loss: 0.3805 - val_acc: 0.8978\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.3901 - acc: 0.8890 - val_loss: 0.3529 - val_acc: 0.8991\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.3648 - acc: 0.8952 - val_loss: 0.3867 - val_acc: 0.8859\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334, 8.579999999999998, 8.53666666666667, 8.506666666666662, 11.31833333333333, 10.495, 10.481666666666667]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17, 8.07, 8.489999999999998, 8.999999999999996, 10.509999999999998, 9.879999999999999, 10.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 222,770\n",
      "Trainable params: 222,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.8685 - acc: 0.7173 - val_loss: 0.6587 - val_acc: 0.7979\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.6381 - acc: 0.8033 - val_loss: 0.6073 - val_acc: 0.8028\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.5486 - acc: 0.8343 - val_loss: 0.5931 - val_acc: 0.8166\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.5307 - acc: 0.8420 - val_loss: 0.5202 - val_acc: 0.8444\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.5299 - acc: 0.8438 - val_loss: 0.5413 - val_acc: 0.8424\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.5212 - acc: 0.8447 - val_loss: 0.5090 - val_acc: 0.8496\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.4580 - acc: 0.8659 - val_loss: 0.4275 - val_acc: 0.8747\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.4364 - acc: 0.8733 - val_loss: 0.4473 - val_acc: 0.8714\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.4758 - acc: 0.8597 - val_loss: 0.4888 - val_acc: 0.8587\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.4414 - acc: 0.8700 - val_loss: 0.4355 - val_acc: 0.8662\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334, 8.579999999999998, 8.53666666666667, 8.506666666666662, 11.31833333333333, 10.495, 10.481666666666667, 12.666666666666671]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17, 8.07, 8.489999999999998, 8.999999999999996, 10.509999999999998, 9.879999999999999, 10.09, 12.529999999999998]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_12 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 236,530\n",
      "Trainable params: 236,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 14s 231us/step - loss: 0.8696 - acc: 0.7251 - val_loss: 0.6248 - val_acc: 0.8099\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.6510 - acc: 0.8025 - val_loss: 0.7373 - val_acc: 0.7799\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.6093 - acc: 0.8156 - val_loss: 0.5676 - val_acc: 0.8310\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.5332 - acc: 0.8406 - val_loss: 0.4997 - val_acc: 0.8513\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.5207 - acc: 0.8499 - val_loss: 0.5636 - val_acc: 0.8360\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.5312 - acc: 0.8446 - val_loss: 0.5321 - val_acc: 0.8370\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.4980 - acc: 0.8571 - val_loss: 0.5380 - val_acc: 0.8317\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334, 8.579999999999998, 8.53666666666667, 8.506666666666662, 11.31833333333333, 10.495, 10.481666666666667, 12.666666666666671, 14.29166666666667]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17, 8.07, 8.489999999999998, 8.999999999999996, 10.509999999999998, 9.879999999999999, 10.09, 12.529999999999998, 14.870000000000005]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 250,290\n",
      "Trainable params: 250,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.9332 - acc: 0.6984 - val_loss: 0.7426 - val_acc: 0.7786\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.6768 - acc: 0.7977 - val_loss: 0.6749 - val_acc: 0.8054\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.6629 - acc: 0.7978 - val_loss: 0.6056 - val_acc: 0.8144\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.5995 - acc: 0.8202 - val_loss: 0.5354 - val_acc: 0.8498\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.6135 - acc: 0.8162 - val_loss: 0.7795 - val_acc: 0.7691\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.6047 - acc: 0.8229 - val_loss: 0.5566 - val_acc: 0.8345\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.5967 - acc: 0.8252 - val_loss: 0.5737 - val_acc: 0.8431\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334, 8.579999999999998, 8.53666666666667, 8.506666666666662, 11.31833333333333, 10.495, 10.481666666666667, 12.666666666666671, 14.29166666666667, 17.476666666666663]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17, 8.07, 8.489999999999998, 8.999999999999996, 10.509999999999998, 9.879999999999999, 10.09, 12.529999999999998, 14.870000000000005, 15.02]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_14 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 264,050\n",
      "Trainable params: 264,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.9408 - acc: 0.6993 - val_loss: 0.8350 - val_acc: 0.7407\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.7716 - acc: 0.7706 - val_loss: 0.6878 - val_acc: 0.8070\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.7144 - acc: 0.7941 - val_loss: 0.7587 - val_acc: 0.7797\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.7398 - acc: 0.7863 - val_loss: 0.6812 - val_acc: 0.7951\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.7574 - acc: 0.7752 - val_loss: 0.9926 - val_acc: 0.6840\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.8462 - acc: 0.7568 - val_loss: 0.8415 - val_acc: 0.7626\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 1.4649 - acc: 0.5021 - val_loss: 2.0956 - val_acc: 0.2268\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334, 8.579999999999998, 8.53666666666667, 8.506666666666662, 11.31833333333333, 10.495, 10.481666666666667, 12.666666666666671, 14.29166666666667, 17.476666666666663, 20.586666666666666]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17, 8.07, 8.489999999999998, 8.999999999999996, 10.509999999999998, 9.879999999999999, 10.09, 12.529999999999998, 14.870000000000005, 15.02, 19.299999999999994]\n"
     ]
    }
   ],
   "source": [
    "n = 15 # number of test\n",
    "for i in range(n):\n",
    "    model = tf.keras.Sequential([])\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28, 1)))\n",
    "    for j in range(i):\n",
    "        model.add(tf.keras.layers.Dense(100, activation='tanh'))\n",
    "    for k in range(i):\n",
    "        model.add(tf.keras.layers.Dense(60, activation='tanh'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    parameters.append(model.count_params())  #count parameters for you\n",
    "\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "                  loss='categorical_crossentropy', #10 classes for output\n",
    "                  metrics=['accuracy']) # add mae: mean average error\n",
    "    model.summary()\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "    # tensorboard = tf.keras.callbacks.TensorBoard(log_dir='logs/{}'.format('model_name'))\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                         batch_size=64,\n",
    "                         epochs=15,\n",
    "                         verbose=1,\n",
    "                         validation_data=(X_val, y_val),\n",
    "                         callbacks=[early_stop])\n",
    "    train_error.append(100*(1-max(hist.history['acc'])))\n",
    "    print('train_error: ', train_error)\n",
    "    test_error.append(100*(1-max(hist.history['val_acc'])))\n",
    "    print('test_error: ', test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter list:  [7850, 85170, 98930, 112690, 126450, 140210, 153970, 167730, 181490, 195250, 209010, 222770, 236530, 250290, 264050]\n",
      "train_error:  [27.125, 7.820000000000005, 10.124999999999995, 8.928333333333338, 8.253333333333334, 8.579999999999998, 8.53666666666667, 8.506666666666662, 11.31833333333333, 10.495, 10.481666666666667, 12.666666666666671, 14.29166666666667, 17.476666666666663, 20.586666666666666]\n",
      "test_error:  [26.280000000000005, 7.279999999999998, 9.78, 8.709999999999996, 8.17, 8.07, 8.489999999999998, 8.999999999999996, 10.509999999999998, 9.879999999999999, 10.09, 12.529999999999998, 14.870000000000005, 15.02, 19.299999999999994]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('parameter list: ', parameters)\n",
    "print('train_error: ', train_error)\n",
    "print('test_error: ', test_error)\n",
    "plot_loss(parameters, train_error, test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 6.4291 - acc: 0.5940 - val_loss: 4.7547 - val_acc: 0.7009\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.6242 - acc: 0.7087 - val_loss: 4.5674 - val_acc: 0.7120\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.4715 - acc: 0.7193 - val_loss: 4.3090 - val_acc: 0.7297\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.4494 - acc: 0.7210 - val_loss: 4.2686 - val_acc: 0.7322\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.3892 - acc: 0.7254 - val_loss: 4.6806 - val_acc: 0.7059\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 4.3526 - acc: 0.7276 - val_loss: 4.2513 - val_acc: 0.7342\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.3319 - acc: 0.7290 - val_loss: 4.2171 - val_acc: 0.7361\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.3123 - acc: 0.7306 - val_loss: 4.7276 - val_acc: 0.7044\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.3306 - acc: 0.7296 - val_loss: 4.2923 - val_acc: 0.7311\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.3040 - acc: 0.7311 - val_loss: 4.1976 - val_acc: 0.7376\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.3055 - acc: 0.7312 - val_loss: 4.1115 - val_acc: 0.7433\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 4.2350 - acc: 0.7356 - val_loss: 4.2647 - val_acc: 0.7333\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 4.2082 - acc: 0.7374 - val_loss: 4.1953 - val_acc: 0.7382\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 4.2714 - acc: 0.7335 - val_loss: 4.1689 - val_acc: 0.7398\n",
      "train_error:  [26.25666666666666]\n",
      "test_error:  [25.670000000000005]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 85,170\n",
      "Trainable params: 85,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.6839 - acc: 0.8337 - val_loss: 0.3503 - val_acc: 0.9023\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.3455 - acc: 0.9001 - val_loss: 0.3273 - val_acc: 0.9047\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.3077 - acc: 0.9076 - val_loss: 0.2969 - val_acc: 0.9076\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2852 - acc: 0.9129 - val_loss: 0.2897 - val_acc: 0.9094\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2788 - acc: 0.9158 - val_loss: 0.2719 - val_acc: 0.9176\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2608 - acc: 0.9214 - val_loss: 0.2667 - val_acc: 0.9188\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2590 - acc: 0.9207 - val_loss: 0.2478 - val_acc: 0.9240\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2548 - acc: 0.9220 - val_loss: 0.2361 - val_acc: 0.9268\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.2425 - acc: 0.9253 - val_loss: 0.2515 - val_acc: 0.9214\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2371 - acc: 0.9254 - val_loss: 0.2400 - val_acc: 0.9260\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2247 - acc: 0.9303 - val_loss: 0.2223 - val_acc: 0.9306\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2262 - acc: 0.9304 - val_loss: 0.2352 - val_acc: 0.9279\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2186 - acc: 0.9331 - val_loss: 0.2065 - val_acc: 0.9398\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.2210 - acc: 0.9321 - val_loss: 0.2275 - val_acc: 0.9316\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2220 - acc: 0.9319 - val_loss: 0.2044 - val_acc: 0.9362\n",
      "train_error:  [26.25666666666666, 6.691666666666663]\n",
      "test_error:  [25.670000000000005, 6.020000000000003]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 98,930\n",
      "Trainable params: 98,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 1.0181 - acc: 0.6865 - val_loss: 0.5669 - val_acc: 0.8257\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.4749 - acc: 0.8577 - val_loss: 0.4512 - val_acc: 0.8609\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.4129 - acc: 0.8751 - val_loss: 0.3613 - val_acc: 0.8934\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.3682 - acc: 0.8874 - val_loss: 0.3325 - val_acc: 0.8976\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.3450 - acc: 0.8936 - val_loss: 0.3113 - val_acc: 0.9069\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.3001 - acc: 0.9090 - val_loss: 0.3099 - val_acc: 0.9083\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2982 - acc: 0.9087 - val_loss: 0.2769 - val_acc: 0.9169\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2763 - acc: 0.9153 - val_loss: 0.2886 - val_acc: 0.9127\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2660 - acc: 0.9171 - val_loss: 0.2605 - val_acc: 0.9206\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2590 - acc: 0.9200 - val_loss: 0.2548 - val_acc: 0.9207\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2465 - acc: 0.9235 - val_loss: 0.2515 - val_acc: 0.9268\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2410 - acc: 0.9256 - val_loss: 0.2348 - val_acc: 0.9300\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2350 - acc: 0.9270 - val_loss: 0.2305 - val_acc: 0.9294\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2355 - acc: 0.9257 - val_loss: 0.2630 - val_acc: 0.9169\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2285 - acc: 0.9297 - val_loss: 0.2434 - val_acc: 0.9275\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 112,690\n",
      "Trainable params: 112,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 1.3895 - acc: 0.4873 - val_loss: 0.8326 - val_acc: 0.7424\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.7065 - acc: 0.7851 - val_loss: 0.6054 - val_acc: 0.8205\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.5463 - acc: 0.8381 - val_loss: 0.5083 - val_acc: 0.8459\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.4635 - acc: 0.8631 - val_loss: 0.4208 - val_acc: 0.8811\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.4161 - acc: 0.8787 - val_loss: 0.3867 - val_acc: 0.8850\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3903 - acc: 0.8849 - val_loss: 0.3853 - val_acc: 0.8849\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3708 - acc: 0.8915 - val_loss: 0.3564 - val_acc: 0.8979\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3531 - acc: 0.8977 - val_loss: 0.3451 - val_acc: 0.8976\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3389 - acc: 0.9003 - val_loss: 0.3300 - val_acc: 0.9038\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3344 - acc: 0.9012 - val_loss: 0.3169 - val_acc: 0.9097\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.3173 - acc: 0.9070 - val_loss: 0.2956 - val_acc: 0.9140\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3088 - acc: 0.9083 - val_loss: 0.2960 - val_acc: 0.9107\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.2868 - acc: 0.9137 - val_loss: 0.2850 - val_acc: 0.9163\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2824 - acc: 0.9150 - val_loss: 0.2650 - val_acc: 0.9230\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2669 - acc: 0.9204 - val_loss: 0.2586 - val_acc: 0.9231\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 126,450\n",
      "Trainable params: 126,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 1.6412 - acc: 0.3506 - val_loss: 1.2013 - val_acc: 0.5563\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.9271 - acc: 0.6802 - val_loss: 0.7295 - val_acc: 0.7584\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.6750 - acc: 0.7854 - val_loss: 0.6146 - val_acc: 0.8087\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.5969 - acc: 0.8186 - val_loss: 0.6000 - val_acc: 0.8125\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.5357 - acc: 0.8403 - val_loss: 0.5177 - val_acc: 0.8510\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.5075 - acc: 0.8527 - val_loss: 0.4812 - val_acc: 0.8603\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.4655 - acc: 0.8662 - val_loss: 0.5164 - val_acc: 0.8453\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.4629 - acc: 0.8666 - val_loss: 0.4524 - val_acc: 0.8737\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.4299 - acc: 0.8752 - val_loss: 0.4182 - val_acc: 0.8868\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.3987 - acc: 0.8863 - val_loss: 0.4020 - val_acc: 0.8898\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.3598 - acc: 0.8983 - val_loss: 0.3800 - val_acc: 0.8931\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.3557 - acc: 0.8999 - val_loss: 0.3580 - val_acc: 0.8986\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.3495 - acc: 0.9007 - val_loss: 0.3577 - val_acc: 0.9010\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3453 - acc: 0.9002 - val_loss: 0.3292 - val_acc: 0.9079\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.3314 - acc: 0.9057 - val_loss: 0.3168 - val_acc: 0.9096\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 140,210\n",
      "Trainable params: 140,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 1.9183 - acc: 0.2336 - val_loss: 1.5596 - val_acc: 0.3513\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 1.4059 - acc: 0.4397 - val_loss: 1.2495 - val_acc: 0.5204\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 1.1658 - acc: 0.5666 - val_loss: 1.0763 - val_acc: 0.6174\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 1.0316 - acc: 0.6429 - val_loss: 1.0294 - val_acc: 0.6291\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.9239 - acc: 0.6932 - val_loss: 0.8344 - val_acc: 0.7328\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.8575 - acc: 0.7304 - val_loss: 0.8437 - val_acc: 0.7410\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.8199 - acc: 0.7497 - val_loss: 0.8386 - val_acc: 0.7547\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.7226 - acc: 0.7936 - val_loss: 0.6921 - val_acc: 0.8151\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.7385 - acc: 0.7894 - val_loss: 0.7469 - val_acc: 0.7819\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.7307 - acc: 0.7930 - val_loss: 0.7711 - val_acc: 0.7842\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.7318 - acc: 0.7957 - val_loss: 0.6776 - val_acc: 0.8105\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.6432 - acc: 0.8283 - val_loss: 0.6003 - val_acc: 0.8432\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.6154 - acc: 0.8374 - val_loss: 0.5572 - val_acc: 0.8586\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.5971 - acc: 0.8433 - val_loss: 0.6525 - val_acc: 0.8223\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.5922 - acc: 0.8371 - val_loss: 0.6021 - val_acc: 0.8302\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672, 15.671666666666662]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003, 14.139999999999997]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 153,970\n",
      "Trainable params: 153,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 7s 111us/step - loss: 2.1975 - acc: 0.1393 - val_loss: 1.9757 - val_acc: 0.1893\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 1.9561 - acc: 0.1957 - val_loss: 1.9472 - val_acc: 0.2087\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 1.9759 - acc: 0.1963 - val_loss: 1.9465 - val_acc: 0.2039\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 1.9151 - acc: 0.2082 - val_loss: 1.7245 - val_acc: 0.2774\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 1.4193 - acc: 0.4196 - val_loss: 1.1876 - val_acc: 0.5281\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 1.1221 - acc: 0.5556 - val_loss: 1.0457 - val_acc: 0.6010\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 1.0052 - acc: 0.6075 - val_loss: 0.9458 - val_acc: 0.6338\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.9281 - acc: 0.6549 - val_loss: 0.8738 - val_acc: 0.6965\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.8308 - acc: 0.7359 - val_loss: 0.7220 - val_acc: 0.7768\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.7716 - acc: 0.7615 - val_loss: 0.7897 - val_acc: 0.7264\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.7500 - acc: 0.7789 - val_loss: 0.7271 - val_acc: 0.7928\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.7235 - acc: 0.7902 - val_loss: 0.6717 - val_acc: 0.8132\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.6742 - acc: 0.8115 - val_loss: 0.6760 - val_acc: 0.8133\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.6940 - acc: 0.8027 - val_loss: 0.7006 - val_acc: 0.7925\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 5s 92us/step - loss: 0.6794 - acc: 0.8105 - val_loss: 0.6244 - val_acc: 0.8290\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672, 15.671666666666662, 18.845]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003, 14.139999999999997, 17.100000000000005]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 167,730\n",
      "Trainable params: 167,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 2.3073 - acc: 0.1054 - val_loss: 2.3038 - val_acc: 0.1032\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 2.3050 - acc: 0.1047 - val_loss: 2.3054 - val_acc: 0.1135\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 2.3043 - acc: 0.1065 - val_loss: 2.3042 - val_acc: 0.1135\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 2.3043 - acc: 0.1066 - val_loss: 2.3035 - val_acc: 0.1010\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672, 15.671666666666662, 18.845, 89.33833333333332]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003, 14.139999999999997, 17.100000000000005, 88.64999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 181,490\n",
      "Trainable params: 181,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 2.3080 - acc: 0.1055 - val_loss: 2.3044 - val_acc: 0.1135\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 2.3047 - acc: 0.1076 - val_loss: 2.3042 - val_acc: 0.1135\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 2.3039 - acc: 0.1066 - val_loss: 2.3038 - val_acc: 0.0974\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 2.3037 - acc: 0.1085 - val_loss: 2.3031 - val_acc: 0.1028\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 2.3034 - acc: 0.1070 - val_loss: 2.3023 - val_acc: 0.1010\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 2.3028 - acc: 0.1087 - val_loss: 2.3018 - val_acc: 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 2.3021 - acc: 0.1110 - val_loss: 2.3014 - val_acc: 0.1135\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 2.3018 - acc: 0.1120 - val_loss: 2.3014 - val_acc: 0.1135\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 2.3016 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672, 15.671666666666662, 18.845, 89.33833333333332, 88.76333333333332]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003, 14.139999999999997, 17.100000000000005, 88.64999999999999, 88.64999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 195,250\n",
      "Trainable params: 195,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 2.3066 - acc: 0.1054 - val_loss: 2.3018 - val_acc: 0.1135\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 2.3052 - acc: 0.1057 - val_loss: 2.3024 - val_acc: 0.1135\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 2.3042 - acc: 0.1056 - val_loss: 2.3036 - val_acc: 0.1135\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 2.3040 - acc: 0.1070 - val_loss: 2.3052 - val_acc: 0.1010\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672, 15.671666666666662, 18.845, 89.33833333333332, 88.76333333333332, 89.3]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003, 14.139999999999997, 17.100000000000005, 88.64999999999999, 88.64999999999999, 88.64999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 209,010\n",
      "Trainable params: 209,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 2.3059 - acc: 0.1036 - val_loss: 2.3048 - val_acc: 0.1135\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 2.3047 - acc: 0.1075 - val_loss: 2.3035 - val_acc: 0.0980\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 2.3045 - acc: 0.1073 - val_loss: 2.3038 - val_acc: 0.1009\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 2.3035 - acc: 0.1072 - val_loss: 2.3031 - val_acc: 0.1135\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 2.3036 - acc: 0.1072 - val_loss: 2.3029 - val_acc: 0.1032\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672, 15.671666666666662, 18.845, 89.33833333333332, 88.76333333333332, 89.3, 89.24833333333333]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003, 14.139999999999997, 17.100000000000005, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 222,770\n",
      "Trainable params: 222,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 2.3076 - acc: 0.1050 - val_loss: 2.3029 - val_acc: 0.0974\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 2.3052 - acc: 0.1052 - val_loss: 2.3030 - val_acc: 0.1135\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 2.3045 - acc: 0.1068 - val_loss: 2.3045 - val_acc: 0.1135\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 2.3040 - acc: 0.1066 - val_loss: 2.3020 - val_acc: 0.1135\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672, 15.671666666666662, 18.845, 89.33833333333332, 88.76333333333332, 89.3, 89.24833333333333, 89.32166666666667]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003, 14.139999999999997, 17.100000000000005, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_12 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 236,530\n",
      "Trainable params: 236,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 15s 242us/step - loss: 2.3066 - acc: 0.1050 - val_loss: 2.3025 - val_acc: 0.1135\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 2.3049 - acc: 0.1056 - val_loss: 2.3027 - val_acc: 0.1135\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 2.3047 - acc: 0.1070 - val_loss: 2.3044 - val_acc: 0.0980\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 2.3041 - acc: 0.1049 - val_loss: 2.3023 - val_acc: 0.1135\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672, 15.671666666666662, 18.845, 89.33833333333332, 88.76333333333332, 89.3, 89.24833333333333, 89.32166666666667, 89.30333333333334]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003, 14.139999999999997, 17.100000000000005, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 250,290\n",
      "Trainable params: 250,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 2.3059 - acc: 0.1035 - val_loss: 2.3041 - val_acc: 0.1135\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 2.3050 - acc: 0.1050 - val_loss: 2.3061 - val_acc: 0.1028\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 2.3045 - acc: 0.1077 - val_loss: 2.3042 - val_acc: 0.1032\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 2.3045 - acc: 0.1058 - val_loss: 2.3036 - val_acc: 0.1028\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672, 15.671666666666662, 18.845, 89.33833333333332, 88.76333333333332, 89.3, 89.24833333333333, 89.32166666666667, 89.30333333333334, 89.23333333333333]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003, 14.139999999999997, 17.100000000000005, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_14 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 264,050\n",
      "Trainable params: 264,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 17s 290us/step - loss: 2.3077 - acc: 0.1043 - val_loss: 2.3031 - val_acc: 0.1135\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 2.3046 - acc: 0.1067 - val_loss: 2.3086 - val_acc: 0.1135\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 2.3045 - acc: 0.1067 - val_loss: 2.3027 - val_acc: 0.1135\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 2.3040 - acc: 0.1062 - val_loss: 2.3012 - val_acc: 0.1135\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 2.3032 - acc: 0.1081 - val_loss: 2.3036 - val_acc: 0.1135\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 2.3030 - acc: 0.1067 - val_loss: 2.3028 - val_acc: 0.1135\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 2.3023 - acc: 0.1098 - val_loss: 2.3015 - val_acc: 0.1135\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672, 15.671666666666662, 18.845, 89.33833333333332, 88.76333333333332, 89.3, 89.24833333333333, 89.32166666666667, 89.30333333333334, 89.23333333333333, 89.025]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003, 14.139999999999997, 17.100000000000005, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999]\n"
     ]
    }
   ],
   "source": [
    "n = 15 # number of test\n",
    "for i in range(n):\n",
    "    model = tf.keras.Sequential([])\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28, 1)))\n",
    "    for j in range(i):\n",
    "        model.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "    for k in range(i):\n",
    "        model.add(tf.keras.layers.Dense(60, activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    parameters.append(model.count_params())  #count parameters for you\n",
    "\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "                  loss='categorical_crossentropy', #10 classes for output\n",
    "                  metrics=['accuracy']) # add mae: mean average error\n",
    "    model.summary()\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "    hist = model.fit(X_train, y_train,\n",
    "                         batch_size=64,\n",
    "                         epochs=15,\n",
    "                         verbose=1,\n",
    "                         validation_data=(X_val, y_val),\n",
    "                         callbacks=[early_stop])\n",
    "    train_error.append(100*(1-max(hist.history['acc'])))\n",
    "    print('train_error: ', train_error)\n",
    "    test_error.append(100*(1-max(hist.history['val_acc'])))\n",
    "    print('test_error: ', test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(parameters_list, train_errors_list, test_errors_list):\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(parameters_list, train_errors_list,'r', label='train error')\n",
    "    ax.plot(parameters_list, test_errors_list,'g', label='test error')\n",
    "    ax.set(xlabel='# parameters', ylabel='validation error (%)')\n",
    "    ax.legend()\n",
    "    plt.title('Sigmoid Multiple Layers')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter list:  [7850, 85170, 98930, 112690, 126450, 140210, 153970, 167730, 181490, 195250, 209010, 222770, 236530, 250290, 264050]\n",
      "train_error:  [26.25666666666666, 6.691666666666663, 7.033333333333336, 7.956666666666667, 9.431666666666672, 15.671666666666662, 18.845, 89.33833333333332, 88.76333333333332, 89.3, 89.24833333333333, 89.32166666666667, 89.30333333333334, 89.23333333333333, 89.025]\n",
      "test_error:  [25.670000000000005, 6.020000000000003, 6.999999999999995, 7.689999999999997, 9.040000000000003, 14.139999999999997, 17.100000000000005, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999, 88.64999999999999]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('parameter list: ', parameters)\n",
    "print('train_error: ', train_error)\n",
    "print('test_error: ', test_error)\n",
    "plot_loss(parameters, train_error, test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## best combination: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 98,930\n",
      "Trainable params: 98,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.6013 - acc: 0.8114 - val_loss: 0.4741 - val_acc: 0.8499\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.4231 - acc: 0.8650 - val_loss: 0.4079 - val_acc: 0.8709\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3871 - acc: 0.8756 - val_loss: 0.3811 - val_acc: 0.8789\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3527 - acc: 0.8888 - val_loss: 0.3084 - val_acc: 0.9005\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3194 - acc: 0.8988 - val_loss: 0.2963 - val_acc: 0.9093\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3118 - acc: 0.9001 - val_loss: 0.2966 - val_acc: 0.9056\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.3044 - acc: 0.9032 - val_loss: 0.2797 - val_acc: 0.9133\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2805 - acc: 0.9110 - val_loss: 0.2811 - val_acc: 0.9122\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2700 - acc: 0.9141 - val_loss: 0.3163 - val_acc: 0.9033\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2825 - acc: 0.9080 - val_loss: 0.3031 - val_acc: 0.9027\n",
      "train_error:  [8.591663837432861]\n",
      "test_error:  [8.670002222061157]\n"
     ]
    }
   ],
   "source": [
    "n = 15 # number of test\n",
    "model = tf.keras.Sequential([])\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28, 1)))\n",
    "model.add(tf.keras.layers.Dense(100, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='tanh'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(60, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(60, activation='tanh'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "parameters.append(model.count_params())  #count parameters for you\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy', #10 classes for output\n",
    "              metrics=['accuracy']) # add mae: mean average error\n",
    "model.summary()\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                         batch_size=64,\n",
    "                         epochs=15,\n",
    "                         verbose=1,\n",
    "                         validation_data=(X_val, y_val),\n",
    "                         callbacks=[early_stop])\n",
    "train_error.append(100*(1-max(hist.history['acc'])))\n",
    "print('train_error: ', train_error)\n",
    "test_error.append(100*(1-max(hist.history['val_acc'])))\n",
    "print('test_error: ', test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My best combination gives me training error of 8.6% and testing error of 8.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. VGG on CIFAR100 and CIFAR10\n",
    "\n",
    "VGG is a simple, but powerful CNN created in 2015. Read the VGG paper here: https://arxiv.org/pdf/1409.1556.pdf\n",
    "\n",
    "Here, we're going to try to reproduce the model's findings on the cifar10 and cifar100 dataset. Note that the paper takes 224 x 224 images, but cifar10 and 100 are only 32 x 32 images.\n",
    "\n",
    "1. Implement all of the layers for the VGG ConvNet Configuration A. Please use the shell code below as guide. Then, train this network on the Cifar10 and Cifar100 datasets.\n",
    "2. For Cifar10 and 100, VGG is probably overkill. Try changing the number of layers and number of filters without sacrificing too much performance accuracy. How many filters can you get rid of before you see the accuracy drop by more than 2%? Where in the architecture is it better to remove filters - towards the input layers, or more towards the output layers?\n",
    "3. For what you experiment with--report the parameter, validation loss curves for changing the number of i) layers, ii) filter size, iii) both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (50000, 32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnWuQXddV59c699x339u332q1Wmq9I9my5UQRjmNIIIQ8hsGhYBgyVQwfUmU+QA0UfCAFVTPM1HyAqiH5MjNMmUpIKBgCQ0LiCmHAGCdOYieOHDuyHrbej251t1rdffu+X+fs+dA3oL3/S1ZLal11n1m/KpV0lvY9Z5991tn33P0/ay02xpCiKIqy+fEedAcURVGU9UEndEVRlIigE7qiKEpE0AldURQlIuiEriiKEhF0QlcURYkIOqEriqJEBJ3QFUVRIsI9TejM/GFmfouZzzHzJ9erU4ryoFHfVjYjfLeRoswcI6IzRPRBIpomou8R0ceNMafWr3uK0nvUt5XNin8Pnz1KROeMMReIiJj5C0T0FBHd0unj8bhJplKWLQgCaOeR/SUTY9xXwscfF3HB5sdi1jYz7oxZ+KEiHLPTwb66X4cx53hERCx8aYYmxH2Fdjv2hE4IhCH2S+rHWvrAwolLNk/Yf8yzx1Ea61AYCyMNtttG/JzNUrFMlVpjbYP29tyxb+fy/WZodMyytRo1aNdpNaxtY7C78UQKbIkk2mLxhLXtCf7SqFfA1mrWwWaE+9C97tI1Zw/vnWxfDmxJp/8m6ECbeh3HC6+y7LeNun1OgbB/0YeE59lOB/cfOvemEfrg+zid+j6OmSF7rKU+hM7u67U6NZut2/r2vUzoE0R09abtaSL6kbf7QDKVosPvfJdlKxaXsJ1nn81gAs94+1AGbCODWbANF/qs7UQsDm38ZBo7G8OhWVougq3Vsfs2UOiHNl7QBluz2QRbo2Hf7Kk03sQB4Y1XE27a/kIebGTsz7aaLWgSIxwf6csh19cHtmzWHv94HPtfF45ppC9Uzx5/qa8dZzL8g898Efdzd9yxbw+NjtHvfup/WrbpN1+FdgsXT1vbQYB+Nrb9HWDbvvsA2Aa2bLe2U2nc15mTL4Ht8rnjYGuX0YdiTt/yA+jbfgrvw6Pv/TGw7dlnn1NjBe/7kydeA1sY4nVvtRtgO3XyDWu7VLwBbZotvOfaLfTtpUX8YqnU7GN2AtzXyMgg2AYG8T4JTNneF04P1Kjb88rXX/gONhK476IoMz/NzMeY+VinLfRcUTYpN/t2ubTyoLujKPc0oc8Q0eRN29u6NgtjzDPGmCPGmCN+HJ/+FGUDcse+ncvj06ui9Jp7WXL5HhHtZeadtOrsv0hE/+7tPtBoNOjkqZOWrXgDfxoNOr/UeQh/ug8HuE7H6VGwVUP7p10lENbROAG2WgN/6tXqwk+2wF4euiEs+Kd8PKa0ThdzlhmSyaTQryruS/hZyo0hsHnOr8u2sOyT9nGsK8Jyx5KwRpnJ2Esu7OEXOAtLXiSsw9Ya9q856dddzLfHp93AteG75I59OwgCKi3bvjZUwJ/gZsReZzc+Lo2Nb9+F+w/x/L3QXhoIa3hNGsuL2Ic6LllMDOO9s31yj7U9uWcHtNk6sQ1so46WQEQUj9vXqlPApZrJbVvA1umg7zWE61xctpeMbtzAJR1f0CaIccllYAjvu1TWPuZKaRnaJFM4nYYGr0nc8dvSirCU23TW7N1F9Vtw1xO6MabDzL9GRH9PRDEi+qwx5uRtPqYoGx71bWWzci9P6GSM+RoRfW2d+qIoGwb1bWUzopGiiqIoEUEndEVRlIhwT0sud4pHRGnfEQ1Rf6Adjgg6NYZvEIwK73ymM/geuhvcUm+iINRoozhohKCYRFp4X73jihe4r/5BFIA6bRRKE3F7/0KsB8USOGDNFp5Tu4P9zzif9bN4Pilh/x1GIdYTAis6TiCKFBDWl8WxqFTxvd+283KuFGPlvioYSgPWK4whcoTbVhOFzFrNFvmm9k1Am0oVx1t693pw2L4v/Dg+n+3duw9sTzx+BGwTYyhu9vePWNttH8c3k0J/Ed4BIO7Y4mC9iu+9NwXhO5NGfxkooIC7e9dBa/v06beETkjxIOh7/fkBsDkxXLRSmoc2hlDAdQOSiIiWl+3rW68J849xt9cW0a9P6IqiKBFBJ3RFUZSIoBO6oihKROjpGjqzoRTba2m5HHZh34S9hjWUxpf/4yGuKVaWcA0rCO3vrLoQfOFhXBHlC5iDwRfWl4srdl4GIT8PDeZwHbBcEtZJnaChegPX/KREVn1Z1A7aLQy+8JzcHHEhcCkQ8s74wmJ4U1gfTrjJokIc62YFAzJICPZKOpe8IwRWrFTttcdAWK/sFSYMqeMEvLCQzC2ZsHWLFSGwbmgLrmdvf2gP2EYnt1rbcXehl0hMFNLu4L3z5iwGINUuLNif8/D+euuNH4Dt3QcOgu3Hjr7b2pbWhEtC+oQrl6+BLSHkCEok7ACt4RHUJq5cPYufE3LRVOp4b5ZK9nXy43hP5PO4LynhmBuTJwUZJpP2tRQkPRF9QlcURYkIOqEriqJEBJ3QFUVRIoJO6IqiKBGhp6Koz0wDSfuQaUGY63cCXkbymKEvEKr0SGElMbdiiJDZrylkshOrjwjBNIFT/cXEcP/Xr2M2taCNvS3XbAGlFqAI1ZcWClc0hYpFhH312KkEJVTBqVdRMMvE8Zi+IGo1nAyV9TaKoqFQgaZYwWMWa/Y1qUiZBNv2WLcEcalXmDCkZs0W0/qEAiX5QTtY552PHoY2k7v2gq3cwfN/68JVa7tUEwozFNH3FosogM7OoViddwKLyMMAmK/+JRYVif8C3gPve8+Tdps43nNbtmwFGxkUjYvLZbB9/zW7aIcfx3klm0M/7giCfKuCY+be1lIxi0C4XxeXsP8e2eKpNNcUnEI5MI/dAn1CVxRFiQg6oSuKokQEndAVRVEiwj2toTPzJSIq0+rydccYg1l/FGUTor6tbEbWQxT9cWME5UI6WIxppGALRbk4LvanUrbNi6FwkRYyH7aFyLzQiaw0Rqgi3sH9By0UbUIjRG46QojxMVqv3MLIsyDA86455ew6AYp85Sr2YWYJ9x/38LP5ij0W7Tm8bPUVFNa2DwtRiqMYzcg5O9KvKZQ/q1SwrytlFEVvrNhi86WrGEUYxGz3bbZQOLxH1uzb7DElk7Z4345hmcR62o5AvljCiN7Xv/UK2JYWMTvhzDU7419ciOiV/KAplnVD2/iIPb7X5y5Dm3xS8PdiCWxnLl609z0+jH2N43Q0Poll6bYKtitztkD81htXoc3o+AjYLl0RLm8bxyxs2bZAyDwpZSpN+vhCR71hfzafF146cMrU8RoXU3TJRVEUJSLc64RuiOgfmPlVZn56PTqkKBsE9W1l03GvSy5PGmNmmHmUiJ5j5jeNMS/e3KB7MzxNRJQSllcUZYNyR75dGMD3khWl19zTE7oxZqb793Ui+hsiOiq0ecYYc8QYcyTh6wqPsjm4U9/O9mF2TkXpNXf9hM7MWSLyjDHl7r9/ioj+y9t9Ju7HaOuIneo1n0Ahqy/jpI4UxEgSIg5ZiORsOukrPSH97FAOS9xlsxjlV1pBAaXfETTKQsrbyzP4uUoTf60knO5PZIRo1TiKaJcWMbKtaYSUw06kaH8eRbsnDuLLHKVZFIBMDce/f9gWgJo17H+lgl/qyTgKR5Nb7L6Njo5Bm/mSLaYunpmDNnfD3fi25/mUydh9vF5E3z531RbrTp08gfsSxMFASFdcL9sCc0wQQOtNFCiLZbSVhZJwl6ZPW9vZNPrL/t37wUaC6Prtb37d2t6xcye02bcfy+UNDeG9mUzh+PTnbRHR66CIXm2i70nl3+pFjEQNAtvXUmn02UoJP5cXolOTzksfLeEFjJoT9RsK6aMl7mXJZYyI/qZbs9Mnov9tjPm/97A/RdkoqG8rm5K7ntCNMReI6NF17IuibAjUt5XNii5qK4qiRITeZluMMQ3m7IAgv4Xrv0lnDTGTxNJOzbpQWksoeVYo2OXspNJXrQC/19ptIeugIHxdW7DX4M5fxrW7hTL2S0geSDucUnsf+1HMxLdtHPvw169eANvL53A9uRPaa5u+h2NRLi6ArVbBdcZcDtcQKbD1iVQK2yRSuLafYWzXcep0bZ/ETHy5JXvN8vhF7HuviMV8KgzawTLnrp6BdrOX7ACbTBzHdqWKmQ8rpetgY2ddtVjGdfBiHf3YT+J4D4+Ngi3taEsTU/ijZVK4nhd/8DLYYmz7XjtAXWbhBgaiHTp0AGx79u7CfjhBQ32PPwZtjr95BWzNBmplzbgQWET2Wnho8AaemxPK5UnZZAfcscZgu3rd1spCQR+U0Cd0RVGUiKATuqIoSkTQCV1RFCUi6ISuKIoSEXorivo+jQ4OWbb6Eoo2HtvdqtSEoAohs57PQgZDp9Sb9A1Wb2MgRGEAAwJaQrmqC9O2ELJUEoJwhAyMMaFUXT5lf3bUx0CF1BKKaHvzmH1udhD3P1+0hbVmDc/7tTMo5HlCabd2ViiF1+8E/3hCAEg/Cty5UChn5wRbmBYGw0w5QWrJ+IN7Pmk2q3T+vJ0l8c3z56Ddtdnz1nZQRkEs158F2/69U2B7+MDD1vbsAgadXV7A/Y9swSCtHbsx0Cc3ZIt388u4L3PjItiuXEbxccEpe3fgIDShD+5DAbRawXMSqk+Sadm+fPI7KMzu3Y8vGYxNFMD2nVdeBNvcvO1/baG8YqOO99OyUC4v3WcfUxI8q045w7UGFukTuqIoSkTQCV1RFCUi6ISuKIoSEXRCVxRFiQg9FkXjNDBsR3QN9GEpOc+zI9mKJYycawvZ4Twh+iwkW0wwQia7vj6MFmsT2k5fQMGw2rTFi1QKI8NSCTxmOovi4EDMFlpePTcPbTot3FezH0XRkQHsPzvRbu0OCtK1FopQVSGzYquDohC74jImtqS4h0bjCZkhffs8O00Ug40jUgtBwD2jWinRd158zrL5Y5iJcPeBQ9Z2uoVi14GDe8G2fx+W/Asa9rgZT7h2hJk+/Tj6RiyG4mC7Y/tytbwEbfqFlxM6wssDV67b93Cqbwb3lR8A267dU2AzwnNovWhnJ3zzu6/j5+o41g9/6MNgO/QIRqLWj9mi6Plzl6BNJoNR3P2FIbCtlqn9F0rC/NZs2udjVBRVFEX5/wud0BVFUSKCTuiKoigR4bYTOjN/lpmvM/OJm2yDzPwcM5/t/o2LX4qywVHfVqLGWkTRzxHRfyeiP73J9kkiet4Y8/vM/Mnu9m/ffldM5AieLJQfc0kKaVgzhNF0vvD95Hm2rU0oLiTTWObqxhxGeNVuoHixa9AWmJqoM1JKEED3757Avjof7sTwvCUBxY9hyt5cAsdnaGC3tb1773Zoc/HK98D25hkUsBK+IFIaW6judNC9PCFqNp7A83Qj40JBYWW2r62gwd6Oz9E6+Xa71aHrV20B8rFH/xW0SybtlwIGhbrp41sxCndJKIt29ZwtUrZCFOQ9xhcFYj7eA4HB60nO9QuaKLqaAPfV1z8MtsWK/fKAJ/hnKKragk3QB/tS9phNbZ2ENqkY7ssjfLni0MMYNVso2KLxs/V/gDZzs3hvToxi2ueA7fs8LryoUSrZIuzp+FVoI3HbJ/RupXNX3n6KiD7f/ffniehjazqaomwg1LeVqHG3a+hjxpjZ7r/naLUGo6JEAfVtZdNyz6KoWS0BdMs3gJn5aWY+xszHyjVhPUJRNih34tsd4b18Rek1dzuhzzPzOBFR92+sj9XFGPOMMeaIMeZILoMBDYqywbgr3/b9nsboKYrI3Xrhs0T0y0T0+92/v7KWD4XGUL1hp0XlNgotRPbTTrWKqVNbbfwu6nj4hVGp2WJSqYbi0sQkDoPpYLsdwyi77d5qC3q1BraZ2Ie1GBMGf60sr9hjk5aizBZRRZvcMg62YhVTne56hx2BmB9AsTY/gClMlxdwLJZXUIiNO0KXZ1Ckawu5T6UguMBJTyoEmEJ92HUKFL0r3/Y8nzJ9g5YtLnSo6KQwTg5ihGZNSFfcEH7cpgdy9r5CYZAaUjpnoVm7BrZU2m7oMaaHDYUUyX1DKAQmjC1VxNL48pBJoG+HjP3iAAVVL2b3I55F8T3dh7ZOE317cQYjtIeytpj91Ec/BG2O/eAS2CpCSt1G065926zjHFjI2X7hxwT1XGAtry3+BRG9TET7mXmamT9Bq87+QWY+S0Q/2d1WlE2F+rYSNW77hG6M+fgt/usD69wXRekp6ttK1NBIUUVRlIjQUyXHkKHACXQwAb4d4K6NplOYkbEvh+u/14QSXBen7fUqX1jYTMxfA1tjfgFse0cxAOYD77fXpc/PYEa63MQI2IaHMEPi9QV77a5QENYKQ+xDQshWeH0Bg4H8VNHaXijOQpuZWQy0iMdxrAt5XOet1501bR+fF1hYDA+FdXWP7Xbs4b6EpH4PjEQiSePb7YAUqc+Nhq0HzZfwFkwUMDCn3cH1Xzcor17Ba9c22AffR22jE0NbJm8H64wOFaGNWcJ7riWUZ+PQ7kc6LWRZFZaJQ4P7CoSsql7cyTwplHisVHG9nAUBJylct5Jzb6Yzg9Dmx97zCNjeOn8ZbCdOzdn9KqHelXAyYoZCmUYJfUJXFEWJCDqhK4qiRASd0BVFUSKCTuiKoigRoaeiaCzmUaFgl2nq+Ch6VCp2FIVpowiyUsbAlstXMCCg4ghF6RR+h81exMClsRSKUBMTO8BW2GoLYfGyECUjZIvc9uhRbDZnC5npDgqzAWGESbWKtvEMCrEtJzMeZ7Fk1rYsBoXkCijglhfnwHZ9ftHabjOed6MlZPXzUPDJJm1RqFUXxFonSyPzXeRbXCcMExm2hbm2IA7WyrYwlxTEwXIJhfVWA8etVrL3FRdOP5dFsXNkAAW9/CAK8CMFu2+Bj1lJ60k8x6Ud6EPNwBHghUCmoCMELgnBUoGH9xg7omhhEAOXwkA4pnCN+vvxmiTY9tFiWRCI2+ijhw/gvVPI2dfkq1/FzI0L83bmzo7QTwl9QlcURYkIOqEriqJEBJ3QFUVRIoJO6IqiKBGhp6JoGHSoXLSFM7+F0Vtxp7QYCRFkUvaxWgWF0oGcLfYUspiRsb6MoujoVsx0OPHI+8B2YtoWcs6cQ2HniXEUoYpFbDe2287K6BGKOK0mCqUFgyJR6foi2NItO5vj+KDQrwBFtPgjKDDVhSjTb3/tWWt7+ir2NSaUm5OKxzlBp9SWygu27fNxI4x7ijFEjqjnh3iN+x33m+zHc3/HLszA2CdES8ec+6RaQqGuUcN7Ip1tg23/XvSFyR3brG0vji8FVIp4zMlxzP65/6KdZTI/iPfh4ACW3vOFkoVS0KRxpgOp7GOngcKioMdTXIrwJVuUHhrGFwoqNbxfq0V8eWBixH5h4WP/+qegzZf/9h+tbd9fp2yLiqIoyuZAJ3RFUZSIsJZ86J9l5uvMfOIm2+8x8wwzv97989H7201FWX/Ut5WosZYn9M8R0YcF+6eNMYe7f762vt1SlJ7wOVLfViLEWgpcvMjMU+t1wJijAQVCBKBxRDKPhBSajCLBMmo9VCo5KV2bKFSN92OU3Lt//MfBtm3/42D70p981treIkRfxlqYYnTmwnmwbdl10NpODe2BNlmDInJtCctepkMUMlt1W7S5UUYRpzCyE2xDW6bAVq+ggOU5piCBEaxS+tx2G68Jd+zoYDYYLdzp2O57p6Loevp2Lpuh973nXZZt10EsPXhtxo4GntiKYuS+vbvBtmVkFGwxY49lWYhebAoRmdI16MviPdDXZwuXsQQKs3FB+K1XUQx/58O2oDq1bwratEO8gY3wzNkJhZTbzsQSi+PU1m6gf4RCBKYnpX1OOWMmtGm2sf9+DF8CCFr2dRoRBNYnf/Td1vbLr7wBbSTuZQ3915j5ePdnK84eirJ5Ud9WNiV3O6H/ERHtJqLDRDRLRH94q4bM/DQzH2PmY5Uafpsrygbj7ny7ir80FaXX3NWEboyZN8YExpiQiP6YiDDT1L+0fcYYc8QYc6Qvg++UKspG4q59W1hqU5Rec1eBRcw8boz5YWTJzxLRibdr/8+fIyInaRkFwrqTW7pLWK4iUxc+JyQ6HByyAwy2ZHDN7J1H9oHtwBO4Xr58HZ/Ckh07cGPXtm3QJhQ6tmUUsyG6gQ81Ifio1cH+t+t4GQPCCeb8zLS1/caJY9DmicfxmENbMMiqVMZ1e7dS3fAUrsuGUim5lrA+7mgdKwvC+nDZPmAoBFjdKXfr25lMmt71yDss20OP4Rp6/WF7fTzbj1qEdBZGyCTpOeuzg1nM7CdUoBOf4kKhFBtk+BPu1WYT9aHde7aDLZ2wfaFexYAn4wnTEaPNuJMIEYWOfhII4yWVcWvVsf9BKJR+9F1dD0exvIh6xeWLV8H23icfs7ZrbdTFMs6avSB7iNx2QmfmvyCi9xPRMDNPE9F/IqL3M/NhIjJEdImIfmVth1OUjYP6thI11vKWy8cF82fuQ18UpaeobytRQyNFFUVRIoJO6IqiKBGhp9kWjSEKnYCRehPFmITzxoDv48v5MQ/Fuz1b8JXhVNr+zpraMQltHn0Sg4jG9z8Cttdf/hOwbZ+0j7nloUPQJjGCgSJ+Bst51Rq26FovoVgyfw1FluX5abAFQkBJOmcHigwP47hevfYa2MbGJ8DWqQkBYXU7Ix1Xl7FfBkUoSeRKJ+2+JbZgX0tJRzjqqTfbeJ5HaSc4py+FmSuzGaeTQhY9KZugVF7Pc2ySKBy2BZsQgOW+iEBE1HHkWUmYM25mVCLqK2CwVMcpfxiEQvZAodycIRTMPakjgW0LhDnDkDCwQtk7DvGYSae/8QDPO9vAczLz6O8LF+xSmdv244sUNzz7/lqrKKpP6IqiKBFBJ3RFUZSIoBO6oihKRNAJXVEUJSL0VEZiZorH7EMuCxn/goatAKQzQvktoXbU6BCWnbo6a0cY7n4nZkvddkjKoIoCa7tcBVt/zhY3R/YdhjZVH0Wik699D2zNur3/klBS7MbMFbDFAhR2Uim8tBM7bXHzkX2YzbETwyi5eAxLosUTQma5hp1dsXZ5Btq4ojgRUUd4rKg4JQYzQ9ivMadMYDz+4J5PYrEY5frt62yETHs1JwLWNJvQpilkBK1W0PdaTpbKZhOvSaeDomhbiPiUMl7WnJJqtSqK9B0hwjQ3iIJ/rt/2oUJuGNqkEpgaJBCyORILGRKdjKy5HJa4W7yO+2oI2V5DIVMpk923MMDrls+hCL5j+xjY6jX7Whohe2S/UzozJojWEvqEriiKEhF0QlcURYkIOqEriqJEBJ3QFUVRIkJvI0XDkJp1WzjLJLELnHKisjyh5FSAtnQfRmr9zL/9GWv7iY98ANrkh1G4mL9wGmwxoR/Fsp0GdOHSW9DmWhmFwK9/+ctg60vbIlqjiYLNljEUnPI5FAwvTmNEacvp/+DWKWiz79C7wEYBij1LRYxOrTli9nIdx4sNXu9GHYW1ihPNaCpYzu6Ao9VKEZa9olgs0Zef/TvLFsS/Ce2Wl+0owcrKDWgj6P2iUDo/b+8rEAZgUChdNzCM6ZCTMbwu1SVblD9zFu+JUgV9dHLnDrDF4rZv53PYh507Me3utklMCbxzF0YuDzpRw7kUCtKhkKqYYjhntIW5Jebk8I4lMXRzbEoQevN477SdcooxoUzE4KDdV1+IKJbQJ3RFUZSIoBO6oihKRLjthM7Mk8z8AjOfYuaTzPzrXfsgMz/HzGe7f2sxXWVTob6tRI21PKF3iOi3jDEHiehxIvpVZj5IRJ8koueNMXuJ6PnutqJsJtS3lUixlopFs7Ra/ZyMMWVmPk1EE0T0FK2W7yIi+jwRfZ2Ifvtt90WGQuOIO0KqSnai2zpGqB8qpFxNJVH0OPwuW+RLxlEsOfU6poxdvnYebM0mCnPl5SVr++q5U9CmYjDSNR7gvvoc4SOfQrFzZABF0dn5ObB1hGjAWtkWsK5exKhTopNgqVQwQjDl4/h3krYAt9jB65FOYwRfJofjk/ZtMalcK+HxnAi7O9VE19O3S+UKPffCS5atsG0/HjOwr8FrL70AbXYIdWmHh1BEnJm2r3tHuJcygxjl2/JQhJ4XRPQPHH2PtX34kYegTU24J7w4TisXr1y2ts+cxfvrjRN4Hxb6sTbuz/38z4LtvQ/ZdYETQjHVbeOYOrsliKIs5Kp1Uw63pbS+vpB2t4D+nnaiPsMYCt7uLCVkTxa5ozV0Zp4ioseI6LtENHZTMd05IsJXRRRlk6C+rUSBNU/ozNxHRF8kot8wxliPS8YYQ7d4QGLmp5n5GDMfq9aFvAyK8oBZD99utTC3h6L0mjVN6Mwcp1WH/3NjzJe65nlmHu/+/zgRXZc+a4x5xhhzxBhzJJsWXrhUlAfIevl2IoHvGytKr7ntGjqv1r76DBGdNsZ86qb/epaIfpmIfr/791dufzhD5JS1CoUSUH7czpoYCBn6WoQv/4/148sIf//sV63twTFcIx6V1tZqK2CLx/Gm7cs6AQAersllhXX7LaO4Jlov2yXb0jE83uICBqK0Wzg+uRSuS7ecIJCzrx2DNrNvngFbs4NltCiO5xk4557dhhoAZfF6e0lch0056+MDhOdz4KGd1nY6dQGP9zasp28PDA7Rv/n4v7dsydG90K5Wtte9z77xA2gzvgX90ROy7aVTtu+1QrxO+x7GPgyMY7BRbRjvnZ/+yE9a25LWURXW0IVKctRxyuM1Ovi569eXwHb54jWwZTKozcxNL1rbl06ehTZeA495YQ6/q4/+1BGw7Zjaam1LwUdeSnhgjQsaoZtdkbFNgu3xWusa+loiRd9LRL9ERG8w8+td2+/QqrP/FTN/goguE9EvrO2QirJhUN9WIsVa3nL5FhHd6vsB4+gVZZOgvq1EDY0UVRRFiQg6oSuKokSEnmZbJMMUOopJQsgilvKdwAfhRX8jlEoLWxhMc+OGLUJVFjAIJ93GoJWQsF+DAyhkFraOWNsdoTTVzDU8phHehPM8+3K0OkLWN0aBNZvC0ntC5TGKuUYhOCtooRjsCSpXqbYMtlbSFuVyW3Esqmksq1d1hGYuAAAQ30lEQVQWyow1qvazxlB+F7QZdoRlXwho6RXMRMmE3eczb56AdqUV2xeMwWvQbuF4VIQSdOwoZakk+ka7hkFhKwt4zPkrGFj0d39vZ49cLgv7qqC/5PIoWvYP2OX5skIWwulpFEBHhzGzYiqPou43/9bu69LZ49AmEOaHc3PzYJsWSu3tPWCLy/15vOf6haC/dAYDi/qz9nWKp3CuyWTs8TFmbaqoPqEriqJEBJ3QFUVRIoJO6IqiKBFBJ3RFUZSI0GMViclje7E/lcToM+NEgWbTKEBkc1juqdbGSLChnB295QsRpq0VFEZCD6O+anFUGsfG7GjFUBC09j+C2fNeeuF57IepWdtxITysXqmBLZ9DESrh46WNOdFnFSFy7uIsip3FIo5Zk1GkG9lnPx9MFIRoVYPjunwDzynRsIWj7IQQWVuzI+xCQQjuFWGnTeVFW/D8p6/8LbS7OmeX7vPaGN15/DiK9FKoYMcVzRkH4Lmv/hPYEkLE8+HH3gm2ViJnbZeaeJ0uXMFIy8VFLFXXath9uzZ3CdpcvISfO/IYlkT8D7/6m2B75TsvW9udlUVoU2qiSF8XXk64cAwF4m++OmttZ30UWOMJFDdjSRzrnCOKbtsxBW2e+rlftLZbnbU9e+sTuqIoSkTQCV1RFCUi6ISuKIoSEXRCVxRFiQg9FUU9Jkr49ndITRAqYk7ptVBII1sTxKRYHAWOZMIW5uJxjDBNZDDCqz+P7eYWUDytTdiC5+jkHmgzcx1T3j707veCrbJgR8pdOIOpfqsVjLT0YzgW/f0olLKTunh2BiPzrlwWIkWTOBb5MRSqRwbtY7IguvIS7mtgGd1wYtSOLNxWQGH53ClbhGzWUajqFfF4gsbHxi3b3qmd0M4418AXysHFBAHUi+Gzlwltf08IJQspjpGKW7di9OX7P/QhsOUy9jXuT2GK3VMnMP3vmXNYXm7LxJS13RBKxMWElx9OnHkTj3kGUzxnpg5Y29euYV8HCmgbTaBIn+lDMX9pzi6htzhzDtos3MD5oREIkcBO5PVsEf3/iQ/YbYQM4iL6hK4oihIRdEJXFEWJCLed0Jl5kplfYOZTzHySmX+9a/89Zp5h5te7fz56/7urKOuH+rYSNdayht4hot8yxnyfmXNE9CozP9f9v08bY/7b/eueotxX1LeVSLGWikWzRDTb/XeZmU8TEaoqazmYzzQ2Yv8oaC9iRFc9sIWiKgYlkvFQJfCF6Mh83o4wTAj1PetVjMxLS6lYW2g79tJL1vau/UI6zmlMn+sJKYEzTvrTmCAGp9MofFUrKIrW62jrOPVb+9K4/yce2we2lBCJ2olh9GjQtiMJ61dRFPXKKNKNZnJge2zfQ3abwhi0eXX2ot2nNvbp7VhP3+50OrS0YNfEfPxHnoB2T7zvfdZ2MonRhb4ggEo1RUOnTmdMSPks1ZuttzDic3H6ItiWGrbIvHQDa35eEATQa9fR3/tG7ZqclEQ/4ASKoq0OvjTx3De+BbYduw9Z25ODQtpdD+/fjBA122xg+twLJfsFhT7hnggM+t/ccgVsw8NT1natjcL4P33jFWu7XBYmQYE7WkNn5ikieoyIvts1/RozH2fmzzIzSsiKsklQ31aiwJondGbuI6IvEtFvGGNKRPRHRLSbiA7T6lPOH97ic08z8zFmPlaqYZ4TRXnQrIdvlyv4VKcovWZNEzozx2nV4f/cGPMlIiJjzLwxJjDGhET0x0R0VPqsMeYZY8wRY8yRfAbf+VSUB8l6+XauD5eNFKXX3HYNnVfrXH2GiE4bYz51k328uwZJRPSzRIT1thwSCabtk/ak3s+4lnbuqr3GNy+UzGoFuPbV14enU63ZgTJBiGtaMeF7bWkB1/bLFVwja7Tt/ceMUJKrD3+xz8/heuR01V5zDoWyU2MjmHWQQwyoWS5i1sRk1h6zQj9OQglh/bYprMOSj1pEtWl/tlURyuWFuP89k1vAtnWLfZ5Xp1GbWFyw/aQj1d17G9bTtz2PKeuUDVssoYbw2vFXre3RUfSNsVHMJNpuC9d42QkyEwK5fME3JnZuBdvkAPrCzBk7w2C1guvZo2N47TJDBbDFUvaac62OfR0f3w62uWvTYLuxiPfY+FZ7jZmF0n6VphB45uM80g7R35OOdpUUgr9aiwu4fw/vgTEnyKrVxJULt/t4NjJrecvlvUT0S0T0BjO/3rX9DhF9nJkPd491iYh+ZY3HVJSNgvq2EinW8pbLt4hIqlD6tfXvjqL0DvVtJWpopKiiKEpE0AldURQlIvQ022LMZ8oP2CJBfQGDHAZGnQCJLAYc3JhHgaYhlH/zE7YYIzShsI0iSDvA/a/UUWjMOsE5jRqKPfUGZltsCccMHJsxGChSKQkl6PKYHS6fxwyS9br92RuLeD59fRi4xEJQC3dQpkn4dj+E2BFKCGW6pvZMga1es/f/4ounoM3xM3b5s3rjzgKL1hOPiZJOicJmAzNjvvSSXXrQCGUT8xm8nm0haKrhBI/5wvPZjqlJsD38+EGw7d6OQmnxqi1Izi2jHyeE4LTdQyiULizYLyMc2v8wtHno0H6wfeHP/hRsPuHbcm3nhYJWC8fVSCkLUziuUtm4qZ27rO3rV9/CfXno2+ks7uvAATt4r1HDFzUmx0et7W8kUFyV0Cd0RVGUiKATuqIoSkTQCV1RFCUi6ISuKIoSEXoqijIz+Sn7kKk8ChyDffb3jF9HgTKexqjAklDKjAJ7X+nUKDaJ476CJgpaiQzuP+7b/Y/FUMBtGtx/qy1Fh9mvRLMQHmYEsSdAE8WFSE5K2AJNcRlF0XoLo+n6C5hZzheEUs8Zixqh4DR/A3OeLAsRuOWqHQ34j1/HUmTzjj7caD04UTQMQ6o5ojMJY/Shj/y0/bkWZtGLCQJoGKAPmZgtwsV8vJdSwgsFc0XMxFkuYlm3pbrdD06hyv3W6xfAtvgyRkzu2mkLnu/esxfatITo0XQCRUUjRM26kadeDO/VUIg4qIc4rn6A479jmy2KNioYSX5QKFv5yquvge3aZVtQrQvpZE3NvjdbQqlOCX1CVxRFiQg6oSuKokQEndAVRVEigk7oiqIoEaGnomgYMlXclKqxPmjXl7UFjnga1cGsEIbY348CR6VUd7YxDWulJkSKNtCWS2Dq2pRT0q4jiBe+j9+bCeGrNO6UI2PGRhkhRbBQWYs6grCTSNsN8wUUzJaWULQsC6JufhDHouaUuDt7CYWjN9+4CraxQRRdx7Y5ffOwD8NO+t/5spAetUd4HlO2z0kNLYjauRE7SrAp+EtKeM5KMAqeJu1E5gr1BsIGRiGWy1hyMZbBazC6206DuzuDkaJnL2IJOmKMmIw7qYVnZq9Am6FhTCUs2Vp1FBGbTVtEr1ZRYG0KEZntJkZe+ym8L8a2jljbl2dxHpm/gmPRqGCq3/MnX7e2h4ZGoI0ZGLS3hXTAEvqEriiKEhF0QlcURYkIt53QmTnFzK8w8w+Y+SQz/+eufSczf5eZzzHzXzILvwkVZQOjvq1EjbWsoTeJ6CeMMZVu/cVvMfPfEdFvEtGnjTFfYOb/RUSfoNXiurek1SKavuzsvIhr4bkRe/03lRaCXXDpnQYH8XQqVXuNrFjENbPlRbxfl3H5l2Ihrg2GztpWEAgZ3YSSVtI3KXt25EPMx/OpB/hJI8TTxIXSY52aXfYucANhiCgQApKKFWwnVaVbcvSKS+dwEIuLuP7ZquLOtvTbGfsO7JiANs7h6Owcrg3fhnXz7TBsUK3sBOcI5fbibDvu/DyusZ49dQlsKR8zMCb67TXuYaGc3dZhzLopBYUN9aMm4sYyNYRso6OjuPY+sXUQbLNzc9b2mTOnoc1UayfYJI2hXMYxq9XsNe3SCvqCtIYetDDIKpbEAKGTJ+yygFLZuNHRMbBNPIJZJUdH7HbDI5idMuX04flvvwBtJG77hG5W+eFIxLt/DBH9BBH9ddf+eSL62JqOqCgbBPVtJWqsaQ2dmWPdmovXieg5IjpPREVj/vnZcJqI8BFKUTY46ttKlFjThG6MCYwxh4loGxEdJaJ3rPUAzPw0Mx9j5mMrFSHpiKI8QNbLt8tlXJZSlF5zR2+5GGOKRPQCEb2HiArM/MNF3m1ENHOLzzxjjDlijDnS3yeUsFGUDcC9+nYuh+8uK0qvua0oyswjRNQ2xhSZOU1EHySiP6BV5/95IvoCEf0yEX3ldvsy7FMQt8WFduIItGuGthDidTCgIdWPqdMKI/iFMeDZiuFgDQNUiksoOBVvoABar+JwBR1HUDX4HRl28JgNIbNcIuFkbvSxD+UG7qsu/PKJGxRtcp4diBN6KBy123iOySwGNaTimAWvkLCPuYsK0ObQoyg47X/kUbBN7dljbR99HJ+Ap6/ZIte3z6OfvB3r6dsUGgqdTJie8Lzkt+1rmhcyfb76nW+AbW4ez42da3D06LugzZPvwftrZQVFxePf/y7Yqg37fM5cwaCwC5cuga1ew2vlZhJN5TGYplQSgtqEsnfVEoqz7mzgx3B+6Be+dLfuRCF2YGgcbKNbbeFy62OHoM2gkG0xEcN7OObahEAsdx7xhPJ2Emt5y2WciD7PzDFafaL/K2PMV5n5FBF9gZn/KxG9RkSfWdMRFWXjoL6tRIrbTujGmONE9Jhgv0Cra46KsilR31aihkaKKoqiRASd0BVFUSICrzWL17ocjHmBiC4T0TAR3ZmCtbHYzP3fzH0nevv+7zDGoNrWA9S3NwSbue9E6+DbPZ3Q//mgzMeMMSi/bxI2c/83c9+JNn7/N3r/bsdm7v9m7jvR+vRfl1wURVEigk7oiqIoEeFBTejPPKDjrhebuf+bue9EG7//G71/t2Mz938z951oHfr/QNbQFUVRlPVHl1wURVEiQs8ndGb+MDO/1a0G88leH/9OYebPMvN1Zj5xk22QmZ9j5rPdv7GywAaAmSeZ+QVmPtWtyPPrXfuG7/9mqyakft07NrNfE91f3+7phN7NmfE/iOgjRHSQiD7OzAd72Ye74HNE9GHH9kkiet4Ys5eInu9ub0Q6RPRbxpiDRPQ4Ef1qd7w3Q/9/WE3oUSI6TEQfZubHaTV51qeNMXuIaJlWqwk9UNSve85m9mui++jbvX5CP0pE54wxF4wxLVrNZvdUj/twRxhjXiSiJcf8FK1WsiHawBVtjDGzxpjvd/9dJqLTtFqsYcP3f5NVE1K/7iGb2a+J7q9v93pCnyCim3NwbtZqMGPGmNnuv+eICIsJbjCYeYpWE1F9lzZJ/zdRNSH16wfEZvRrovvn2yqK3iNm9TWhDf2qEDP3EdEXieg3jDFWEvSN3P97qSak3Bsb2S9+yGb1a6L759u9ntBniGjypu1bVoPZ4Mwz8zgRUffv6w+4P7ekW83+i0T058aYL3XNm6b/RHdXTajHqF/3mCj4NdH6+3avJ/TvEdHerpqbIKJfJKJne9yH9eBZWq1kQ7TWijYPAGZmWi3OcNoY86mb/mvD95+ZR5i50P33D6sJnaZ/qSZEtHH6rn7dQzazXxPdZ982xvT0DxF9lIjO0Oqa0e/2+vh30d+/IKJZImrT6rrWJ4hoiFZV9LNE9I9ENPig+3mLvj9Jqz87jxPR690/H90M/SeiR2i1WtBxIjpBRP+xa99FRK8Q0Tki+j9ElHzQfe32S/26d33ftH7d7f99822NFFUURYkIKooqiqJEBJ3QFUVRIoJO6IqiKBFBJ3RFUZSIoBO6oihKRNAJXVEUJSLohK4oihIRdEJXFEWJCP8PFjsMNFEiDLwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is the same model in the other notebook, looks very simplified.\n",
    "import tensorflow as tf\n",
    "(X_train, y_train), (X_val, y_val) = tf.keras.datasets.cifar10.load_data() #32*32 RGB vectors\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, 10)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "X_val = X_val.reshape(X_val.shape[0], 32, 32, 3)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('Training data shape', X_train.shape)\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train[0].reshape(32, 32, 3));\n",
    "ax2.imshow(X_train[1].reshape(32, 32, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 256)         819456    \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 256)         1638656   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 4, 4, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 2, 2, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 2, 2, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 32,816,810\n",
      "Trainable params: 32,816,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Example CNN used in class\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 116s 2ms/sample - loss: 1.6366 - acc: 0.3725 - val_loss: 1.2899 - val_acc: 0.5219\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 1.1345 - acc: 0.5931 - val_loss: 1.0579 - val_acc: 0.6259\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 0.8644 - acc: 0.6943 - val_loss: 0.9299 - val_acc: 0.6775\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 0.6509 - acc: 0.7725 - val_loss: 0.9110 - val_acc: 0.6934\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 0.4694 - acc: 0.8336 - val_loss: 0.9473 - val_acc: 0.7093\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 111s 2ms/sample - loss: 0.3184 - acc: 0.8906 - val_loss: 1.0338 - val_acc: 0.7130\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 112s 2ms/sample - loss: 0.2284 - acc: 0.9235 - val_loss: 1.1428 - val_acc: 0.7215\n"
     ]
    }
   ],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight is 32,816,810; train_acc:0.9235; test_acc:0.7215"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change of layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         819456    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         1638656   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 26,000,042\n",
      "Trainable params: 26,000,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Example CNN used in class\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 86s 2ms/sample - loss: 1.5350 - acc: 0.4414 - val_loss: 1.1503 - val_acc: 0.5850\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 84s 2ms/sample - loss: 1.0675 - acc: 0.6221 - val_loss: 0.9922 - val_acc: 0.6514\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 84s 2ms/sample - loss: 0.8216 - acc: 0.7119 - val_loss: 0.8966 - val_acc: 0.6798\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 84s 2ms/sample - loss: 0.6256 - acc: 0.7825 - val_loss: 0.8497 - val_acc: 0.7169\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 84s 2ms/sample - loss: 0.4434 - acc: 0.8454 - val_loss: 0.9373 - val_acc: 0.7093\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 84s 2ms/sample - loss: 0.2994 - acc: 0.8954 - val_loss: 0.9601 - val_acc: 0.7277\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 84s 2ms/sample - loss: 0.2061 - acc: 0.9290 - val_loss: 1.1082 - val_acc: 0.7187\n"
     ]
    }
   ],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 256)         819456    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 256)         1638656   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 24,557,226\n",
      "Trainable params: 24,557,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 43s 856us/sample - loss: 1.7898 - acc: 0.4572 - val_loss: 1.1860 - val_acc: 0.5785\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 42s 849us/sample - loss: 1.0452 - acc: 0.6299 - val_loss: 1.0747 - val_acc: 0.6234\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 43s 850us/sample - loss: 0.8149 - acc: 0.7140 - val_loss: 0.9765 - val_acc: 0.6721\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 42s 848us/sample - loss: 0.6177 - acc: 0.7829 - val_loss: 0.9038 - val_acc: 0.6938\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 42s 849us/sample - loss: 0.4307 - acc: 0.8498 - val_loss: 0.9201 - val_acc: 0.7072\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 43s 852us/sample - loss: 0.2883 - acc: 0.9003 - val_loss: 1.0075 - val_acc: 0.7062\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 43s 850us/sample - loss: 0.1962 - acc: 0.9314 - val_loss: 1.2195 - val_acc: 0.6941\n"
     ]
    }
   ],
   "source": [
    "# Example CNN used in class\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "\n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 512)         1638912   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 47,069,354\n",
      "Trainable params: 47,069,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 75s 1ms/sample - loss: 14.4812 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 74s 1ms/sample - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "# Example CNN used in class\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 256)       409856    \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 512)         6554112   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 50,551,338\n",
      "Trainable params: 50,551,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 1.5925 - acc: 0.4681 - val_loss: 1.2420 - val_acc: 0.5588\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 0.9703 - acc: 0.6603 - val_loss: 0.9138 - val_acc: 0.6798\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 0.7219 - acc: 0.7465 - val_loss: 0.8249 - val_acc: 0.7197\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 0.5230 - acc: 0.8160 - val_loss: 0.8535 - val_acc: 0.7222\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 0.3399 - acc: 0.8836 - val_loss: 0.8914 - val_acc: 0.7273\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 103s 2ms/sample - loss: 0.2094 - acc: 0.9277 - val_loss: 0.9459 - val_acc: 0.7440\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(128, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4096)              67112960  \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 72,225,834\n",
      "Trainable params: 72,225,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 39s 775us/sample - loss: 14.5063 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 39s 772us/sample - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 38s 769us/sample - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 39s 772us/sample - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(128, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(256, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "\n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(512, (5,5), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots for changing layers and conclusions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer: I can take out 4 convolution layers + 2 Max pooling layers before the test accuracy dropped by 2%. Changing more towards the output layers is much better than changing more towards the input layers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change filter size and conclusions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 16,429,738\n",
      "Trainable params: 16,429,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 45s 895us/sample - loss: 1.5239 - acc: 0.4360 - val_loss: 1.3274 - val_acc: 0.5125\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 1.0713 - acc: 0.6194 - val_loss: 1.0431 - val_acc: 0.6360\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.8404 - acc: 0.7066 - val_loss: 0.8732 - val_acc: 0.6994\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 43s 866us/sample - loss: 0.6641 - acc: 0.7684 - val_loss: 0.8790 - val_acc: 0.7012\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.4999 - acc: 0.8276 - val_loss: 0.8474 - val_acc: 0.7286\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 43s 868us/sample - loss: 0.3724 - acc: 0.8715 - val_loss: 0.8947 - val_acc: 0.7327\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 43s 865us/sample - loss: 0.2638 - acc: 0.9110 - val_loss: 0.9866 - val_acc: 0.7257\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 43s 864us/sample - loss: 0.1909 - acc: 0.9356 - val_loss: 1.0159 - val_acc: 0.7377\n"
     ]
    }
   ],
   "source": [
    "# Example CNN used in class\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_35 (Conv2D)           (None, 32, 32, 64)        3136      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 8, 8, 256)         524544    \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 8, 8, 256)         1048832   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 4, 4, 512)         2097664   \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 4, 4, 512)         4194816   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 2, 2, 512)         4194816   \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 2, 2, 512)         4194816   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 23,599,082\n",
      "Trainable params: 23,599,082\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 92s 2ms/sample - loss: 1.5698 - acc: 0.4123 - val_loss: 1.2580 - val_acc: 0.5291\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 90s 2ms/sample - loss: 1.0873 - acc: 0.6113 - val_loss: 1.0877 - val_acc: 0.6221\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 90s 2ms/sample - loss: 0.8421 - acc: 0.7035 - val_loss: 1.0016 - val_acc: 0.6579\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 90s 2ms/sample - loss: 0.6471 - acc: 0.7742 - val_loss: 0.9220 - val_acc: 0.6846\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 90s 2ms/sample - loss: 0.4712 - acc: 0.8366 - val_loss: 0.8787 - val_acc: 0.7148\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 90s 2ms/sample - loss: 0.3341 - acc: 0.8839 - val_loss: 1.0462 - val_acc: 0.7048\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 91s 2ms/sample - loss: 0.2406 - acc: 0.9187 - val_loss: 1.1792 - val_acc: 0.7042\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 91s 2ms/sample - loss: 0.1851 - acc: 0.9371 - val_loss: 1.1593 - val_acc: 0.7215\n"
     ]
    }
   ],
   "source": [
    "# Example CNN used in class\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (4,4), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (4,4), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (4,4), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (4,4), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (4,4), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (4,4), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, (4,4), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (4,4), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        6976      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         2359552   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         4719104   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         9437696   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 2, 2, 512)         9437696   \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 512)         9437696   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 44,082,922\n",
      "Trainable params: 44,082,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 154s 3ms/sample - loss: 1.7090 - acc: 0.3213 - val_loss: 1.5015 - val_acc: 0.4626\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 148s 3ms/sample - loss: 1.2031 - acc: 0.5670 - val_loss: 1.0563 - val_acc: 0.6188\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 148s 3ms/sample - loss: 0.9089 - acc: 0.6809 - val_loss: 0.9491 - val_acc: 0.6684\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 148s 3ms/sample - loss: 0.7020 - acc: 0.7551 - val_loss: 0.8973 - val_acc: 0.6986\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 148s 3ms/sample - loss: 0.5081 - acc: 0.8236 - val_loss: 0.9959 - val_acc: 0.6988\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 148s 3ms/sample - loss: 0.3601 - acc: 0.8758 - val_loss: 1.0827 - val_acc: 0.6977\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 148s 3ms/sample - loss: 0.2561 - acc: 0.9135 - val_loss: 1.1168 - val_acc: 0.7061\n"
     ]
    }
   ],
   "source": [
    "# Example CNN used in class\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (6,6), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 64)        9472      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 128)       401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 256)         1605888   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 256)         3211520   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 512)         6423040   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 4, 4, 512)         12845568  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 512)         12845568  \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 2, 2, 512)         12845568  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 57,397,418\n",
      "Trainable params: 57,397,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 184s 4ms/sample - loss: 1.7731 - acc: 0.2972 - val_loss: 1.6043 - val_acc: 0.4129\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 181s 4ms/sample - loss: 1.3063 - acc: 0.5268 - val_loss: 1.1503 - val_acc: 0.5922\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 181s 4ms/sample - loss: 0.9945 - acc: 0.6503 - val_loss: 1.0041 - val_acc: 0.6546\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 181s 4ms/sample - loss: 0.7743 - acc: 0.7298 - val_loss: 0.9954 - val_acc: 0.6680\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 182s 4ms/sample - loss: 0.5697 - acc: 0.8042 - val_loss: 0.9959 - val_acc: 0.6890\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 181s 4ms/sample - loss: 0.4054 - acc: 0.8608 - val_loss: 1.0582 - val_acc: 0.6920\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 181s 4ms/sample - loss: 0.2806 - acc: 0.9070 - val_loss: 1.1873 - val_acc: 0.6885\n"
     ]
    }
   ],
   "source": [
    "# Example CNN used in class\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (7,7), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(parameters_list, train_errors_list, test_errors_list):\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(parameters_list, train_errors_list,'r', label='train error')\n",
    "    ax.plot(parameters_list, test_errors_list,'g', label='test error')\n",
    "    ax.set(xlabel='# Filter Size', ylabel='Validation Error (%)')\n",
    "    ax.legend()\n",
    "    plt.title('Changing Filter Size')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter_size = [3, 4, 5, 6, 7]\n",
    "train_error_list = [100-93.56, 100-93.71, 100-92.35, 100-91.35, 100-90.70]\n",
    "test_error_list = [100-73.77, 100-72.15, 100-72.15, 100-70.61, 100-69.20]\n",
    "plot_loss(filter_size, train_error_list, test_error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(parameters_list, train_errors_list, test_errors_list):\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(parameters_list, train_errors_list,'r', label='train error')\n",
    "    ax.plot(parameters_list, test_errors_list,'g', label='test error')\n",
    "    ax.set(xlabel='# parameters', ylabel='validation error (%)')\n",
    "    ax.legend()\n",
    "    plt.title('Changing Layers Parameters')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = [32816180, 26000042, 24557226, 50551338, 72274346]\n",
    "train_error_list = [100-92.35, 100-92.90, 100-93.14, 100-92.77, 90]\n",
    "test_error_list = [100-72.15, 100-71.87, 100-70.72, 100-74.40, 90]\n",
    "plot_loss(params, train_error_list, test_error_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        9472      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       401536    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         1605888   \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         3211520   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 512)         6423040   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 512)         12845568  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 37,997,738\n",
      "Trainable params: 37,997,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 125s 2ms/sample - loss: 1.5533 - acc: 0.4313 - val_loss: 1.2320 - val_acc: 0.5514\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 122s 2ms/sample - loss: 1.1161 - acc: 0.6056 - val_loss: 1.0832 - val_acc: 0.6202\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 122s 2ms/sample - loss: 0.8518 - acc: 0.7040 - val_loss: 0.9476 - val_acc: 0.6743\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 122s 2ms/sample - loss: 0.6425 - acc: 0.7754 - val_loss: 0.9039 - val_acc: 0.6993\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 122s 2ms/sample - loss: 0.4461 - acc: 0.8475 - val_loss: 0.9773 - val_acc: 0.7002\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 122s 2ms/sample - loss: 0.2838 - acc: 0.9031 - val_loss: 1.1237 - val_acc: 0.6847\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 122s 2ms/sample - loss: 0.1975 - acc: 0.9334 - val_loss: 1.3196 - val_acc: 0.6858\n"
     ]
    }
   ],
   "source": [
    "# Example CNN used in class\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (7,7), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (7,7), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(512, (7,7), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(512, (7,7), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        6976      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 128)       295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 256)         2359552   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 512)         4719104   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 512)         9437696   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 31,498,986\n",
      "Trainable params: 31,498,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 107s 2ms/sample - loss: 1.5298 - acc: 0.4367 - val_loss: 1.2511 - val_acc: 0.5567\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 1.0760 - acc: 0.6162 - val_loss: 1.0062 - val_acc: 0.6462\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.8280 - acc: 0.7112 - val_loss: 0.9396 - val_acc: 0.6745\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.6155 - acc: 0.7850 - val_loss: 0.8874 - val_acc: 0.7127\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.4344 - acc: 0.8475 - val_loss: 0.8957 - val_acc: 0.7132\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.2929 - acc: 0.8982 - val_loss: 1.1201 - val_acc: 0.7076\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 105s 2ms/sample - loss: 0.2079 - acc: 0.9297 - val_loss: 1.0682 - val_acc: 0.7035\n"
     ]
    }
   ],
   "source": [
    "# Example CNN used in class\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (6,6), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(512, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(512, (6,6), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(padding='same'),\n",
    "    \n",
    "#     tf.keras.layers.Conv2D(512, (7,7), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.Conv2D(512, (7,7), padding='same', activation='relu'),\n",
    "#     tf.keras.layers.MaxPool2D(padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=3)\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 batch_size=64,\n",
    "                 epochs=30,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_val, y_val),\n",
    "                 callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: Decrease filter size and reduce layers from output side will first increase and then decrease the accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Part 4, state of the art\n",
    "\n",
    "Currently, state of the art implementations in the image classification problem are DenseNet: (https://arxiv.org/abs/1608.06993), ResNet (https://arxiv.org/abs/1512.03385), and ResNext (https://arxiv.org/pdf/1611.05431.pdf). Try implementing and training one of these on the cifar10 and cifar100 dataset. Feel free to experiment.\n",
    "\n",
    "Jargon to learn about\n",
    "1. What is \"residual learning\"?\n",
    "\n",
    "\n",
    "2. What is a \"bottleneck layer\"?\n",
    "\n",
    "\n",
    "3. What is a \"dense block\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
